{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valerie task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def col_discretize(nrows):\n",
    "    \n",
    "    ages = np.random.randint(1,40, nrows)\n",
    "    \n",
    "    def age_filter(num):\n",
    "        if num < 18:\n",
    "            return \"Under 18\"\n",
    "        elif num >= 18 and num < 26:\n",
    "            return \"18-25\"\n",
    "        elif num >= 26 and num < 35:\n",
    "            return \"26-34\"\n",
    "        else:\n",
    "            return \"35 and Above\"\n",
    "    \n",
    "    new_ages = [age_filter(num) for num in ages]\n",
    "    \n",
    "    return pd.DataFrame({'age':ages}), pd.DataFrame({'age':new_ages})\n",
    "\n",
    "def col_onehot(nrows):\n",
    "    \n",
    "    from random import choices \n",
    "  \n",
    "    colors = ['brown', 'green', 'blue']\n",
    "    lst = choices(colors,k=nrows)\n",
    "    one_hot = pd.get_dummies(lst)\n",
    "    \n",
    "    return pd.DataFrame({'color':lst}), one_hot\n",
    "    \n",
    "\n",
    "def process_date(nrows):\n",
    "    \n",
    "    '''\n",
    "    2019-03-22 00:00:00 --> 2019, 03, 22\n",
    "    '''\n",
    "    \n",
    "    # if we want more rows, that would be a problem.. \n",
    "    \n",
    "    from datetime import date, timedelta\n",
    "    sdate = date(2019,3,1)   # start date\n",
    "    edate = date(2019,3,1+nrows)   # end date\n",
    "    dates = pd.date_range(sdate,edate-timedelta(days=1),freq='d').tolist()\n",
    "    random.shuffle(dates)\n",
    "    \n",
    "\n",
    "    d_old = {'dates': dates}\n",
    "    df = pd.DataFrame(data=d_old)\n",
    "    df_temp = pd.to_datetime(df['dates'],format='%Y-%m-%d')\n",
    "    \n",
    "    d_new = {'year': df_temp.dt.year, 'month': df_temp.dt.month, 'day':df_temp.dt.day}\n",
    "    df_new = pd.DataFrame(data=d_new)\n",
    "         \n",
    "    return df.reset_index(drop=True) , df_new.reset_index(drop=True) \n",
    "    #return df.sa(n=nrows, random_state=1), df_new.choices(n=nrows, random_state=1)\n",
    "\n",
    "\n",
    "def round_number(nrows):\n",
    "    \n",
    "    '''\n",
    "    round generated list to a randomly generated number of digits\n",
    "    '''\n",
    "    \n",
    "    round_digits = np.random.randint(4)\n",
    "    \n",
    "    orig = np.random.rand(nrows)*10\n",
    "    mod = orig.round(round_digits)\n",
    "    \n",
    "    return pd.DataFrame({'height':orig}), pd.DataFrame({'height':mod})\n",
    "\n",
    "def col_drop(df):\n",
    "    \n",
    "    '''\n",
    "    given df, randomly drop between 1-4 columns\n",
    "    '''\n",
    "    \n",
    "    from random import sample\n",
    "    num_cols_to_drop = np.random.randint(1,4)\n",
    "    cols_to_drop = sample(df.columns.tolist(), num_cols_to_drop)\n",
    "\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "def create_datasets(rand_seed):\n",
    "    \n",
    "    random.seed(rand_seed)\n",
    "    np.random.seed(rand_seed) \n",
    "    \n",
    "    nrows = 10\n",
    "    \n",
    "    fns_to_apply = [\"col_discretize\", \"col_onehot\", \"process_date\", \"round_number\"]\n",
    "    \n",
    "    orig_df = pd.DataFrame()\n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for fn in fns_to_apply:\n",
    "        orig, new = globals()[fn](nrows)\n",
    "        \n",
    "        orig_df = pd.concat([orig_df, orig], axis=1)\n",
    "        new_df = pd.concat([new_df, new], axis=1)\n",
    "                \n",
    "    \n",
    "    new_df = col_drop(new_df)\n",
    "    \n",
    "    return orig_df, new_df\n",
    "\n",
    "def evaluate_correctness(target_df, input_df):\n",
    "    score = 0\n",
    "    for col in target_df.columns:\n",
    "        if col not in input_df.columns:\n",
    "            score -=1 \n",
    "        else:\n",
    "            if np.all(target_df[col] != input_df[col]):\n",
    "                score-=1\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+---------+---------------------+----------+\n",
      "|    |   age | color   | dates               |   height |\n",
      "|----+-------+---------+---------------------+----------|\n",
      "|  0 |     1 | blue    | 2019-03-06 00:00:00 |  2.72656 |\n",
      "|  1 |     4 | blue    | 2019-03-05 00:00:00 |  4.77665 |\n",
      "|  2 |     4 | green   | 2019-03-10 00:00:00 |  8.12169 |\n",
      "|  3 |    10 | brown   | 2019-03-07 00:00:00 |  4.79977 |\n",
      "|  4 |    20 | green   | 2019-03-01 00:00:00 |  3.92785 |\n",
      "+----+-------+---------+---------------------+----------+\n",
      "+----+----------+--------+---------+---------+---------+-------+----------+\n",
      "|    | age      |   blue |   brown |   green |   month |   day |   height |\n",
      "|----+----------+--------+---------+---------+---------+-------+----------|\n",
      "|  0 | Under 18 |      1 |       0 |       0 |       3 |     6 |        3 |\n",
      "|  1 | Under 18 |      1 |       0 |       0 |       3 |     5 |        5 |\n",
      "|  2 | Under 18 |      0 |       0 |       1 |       3 |    10 |        8 |\n",
      "|  3 | Under 18 |      0 |       1 |       0 |       3 |     7 |        5 |\n",
      "|  4 | 18-25    |      0 |       0 |       1 |       3 |     1 |        4 |\n",
      "+----+----------+--------+---------+---------+---------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "orig_df, new_df = create_datasets(seed)\n",
    "evaluate_correctness(orig_df, new_df)\n",
    "from tabulate import tabulate\n",
    "\n",
    "#get the text form of each dataframe\n",
    "txt = tabulate(orig_df.head(), headers = 'keys', tablefmt = 'psql')\n",
    "txt_new = tabulate(new_df.head(), headers = 'keys', tablefmt = 'psql')\n",
    "print(txt)\n",
    "print(txt_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age,blue,brown,green,month,day,height\n",
      "Under 18,1,0,0,3,6,3\n",
      "Under 18,1,0,0,3,5,5\n",
      "Under 18,0,0,1,3,10,8\n",
      "Under 18,0,1,0,3,7,5\n",
      "18-25,0,0,1,3,1,4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Original dataset\n",
    "data = \"\"\"\n",
    "age,color,dates,height\n",
    "1,blue,2019-03-06,2.72656\n",
    "4,blue,2019-03-05,4.77665\n",
    "4,green,2019-03-10,8.12169\n",
    "10,brown,2019-03-07,4.79977\n",
    "20,green,2019-03-01,3.92785\n",
    "\"\"\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "orig_df = pd.read_csv(StringIO(data))\n",
    "\n",
    "df = orig_df.copy()\n",
    "# Process the dataset to match the desired format\n",
    "# 1. Convert 'age' to categorical data\n",
    "df['age'] = pd.cut(df['age'], bins=[0, 18, 25, 100], labels=[\"Under 18\", \"18-25\", \"Over 25\"], right=False)\n",
    "\n",
    "# 2. Convert 'color' to one-hot encoding\n",
    "color_dummies = pd.get_dummies(df['color'])\n",
    "df = pd.concat([df, color_dummies], axis=1)\n",
    "\n",
    "# 3. Extract 'month' and 'day' from 'dates'\n",
    "df['dates'] = pd.to_datetime(df['dates'])\n",
    "df['month'] = df['dates'].dt.month\n",
    "df['day'] = df['dates'].dt.day\n",
    "\n",
    "# 4. Round 'height' to nearest integer\n",
    "df['height'] = df['height'].round().astype(int)\n",
    "\n",
    "# 5. Drop the original 'color' and 'dates' columns\n",
    "df.drop(['color', 'dates'], axis=1, inplace=True)\n",
    "\n",
    "# Rearrange columns to match the desired format\n",
    "df = df[['age', 'blue', 'brown', 'green', 'month', 'day', 'height']]\n",
    "\n",
    "df\n",
    "# convert to string\n",
    "df_str = df.to_csv(index=False)\n",
    "print(df_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Original dataset\n",
    "data = \"\"\"\n",
    "age,color,dates,height\n",
    "1,blue,2019-03-06,2.72656\n",
    "4,blue,2019-03-05,4.77665\n",
    "4,green,2019-03-10,8.12169\n",
    "10,brown,2019-03-07,4.79977\n",
    "20,green,2019-03-01,3.92785\n",
    "\"\"\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "def transform_df(df):\n",
    "    # Process the dataset to match the desired format\n",
    "    # 1. Convert 'age' to categorical data\n",
    "    df['age'] = pd.cut(df['age'], bins=[0, 18, 25, 100], labels=[\"Under 18\", \"18-25\", \"Over 25\"], right=False)\n",
    "\n",
    "    # 2. Convert 'color' to one-hot encoding\n",
    "    color_dummies = pd.get_dummies(df['color'])\n",
    "    df = pd.concat([df, color_dummies], axis=1)\n",
    "\n",
    "    # 3. Extract 'month' and 'day' from 'dates'\n",
    "    df['dates'] = pd.to_datetime(df['dates'])\n",
    "    df['month'] = df['dates'].dt.month\n",
    "    df['day'] = df['dates'].dt.day\n",
    "\n",
    "    # 4. Round 'height' to nearest integer\n",
    "    df['height'] = df['height'].round().astype(int)\n",
    "\n",
    "    # 5. Drop the original 'color' and 'dates' columns\n",
    "    df.drop(['color', 'dates'], axis=1, inplace=True)\n",
    "\n",
    "    # Rearrange columns to match the desired format\n",
    "    df = df[['age', 'blue', 'brown', 'green', 'month', 'day', 'height']]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[1;32m     27\u001b[0m new_data_df_testing \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(StringIO(new_data_testing))\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m evaluate_correctness(new_data_df_testing, transform_df(df)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = \"\"\"\n",
    "age,color,dates,height\n",
    "1,blue,2019-03-06,2.72656\n",
    "4,blue,2019-03-05,4.77665\n",
    "4,green,2019-03-10,8.12169\n",
    "10,brown,2019-03-07,4.79977\n",
    "20,green,2019-03-01,3.92785\n",
    "\"\"\"\n",
    "df = pd.read_csv(StringIO(data))\n",
    "new_data_testing = \"\"\"\n",
    "age,blue,brown,green,month,day,height\n",
    "Under 18,1,0,0,3,6,3\n",
    "Under 18,1,0,0,3,5,5\n",
    "Under 18,0,0,1,3,10,8\n",
    "Under 18,0,1,0,3,7,5\n",
    "18-25,0,0,1,3,1,4\n",
    "\"\"\"\n",
    "def evaluate_correctness(target_df, input_df):\n",
    "    score = 0\n",
    "    for col in target_df.columns:\n",
    "        if col not in input_df.columns:\n",
    "            score -=1 \n",
    "        else:\n",
    "            if np.all(target_df[col] != input_df[col]):\n",
    "                score-=1\n",
    "    return score\n",
    "new_data_df_testing = pd.read_csv(StringIO(new_data_testing))\n",
    "assert evaluate_correctness(new_data_df_testing, transform_df(df)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1,col2,col3,col4,col5\n",
      "6,4,0.5671297731744318,10,4\n",
      "1,6,2.726562945801132,9,6\n",
      "4,3,4.776651173213499,10,1\n",
      "4,5,8.121687287754932,5,3\n",
      "8,8,4.799771723750573,4,4\n",
      "10,7,3.9278479610082973,1,9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define the number of rows\n",
    "n_rows = 6\n",
    "\n",
    "# Create the DataFrame with random data\n",
    "np.random.seed(0)  # Set seed for reproducibility\n",
    "df_random = pd.DataFrame({\n",
    "    'col1': np.random.randint(1, 11, size=n_rows),\n",
    "    'col2': np.random.randint(1, 11, size=n_rows),\n",
    "    'col3': np.random.uniform(0, 10, size=n_rows),\n",
    "    'col4': np.random.randint(1, 11, size=n_rows),\n",
    "    'col5': np.random.randint(1, 11, size=n_rows)\n",
    "})\n",
    "# remove index column\n",
    "df_random.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_str = df_random.to_csv(index=False)\n",
    "print(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1,col2,col3,col4\n",
      "60,0,0.5671297731744318,1000\n",
      "9,2,2.726562945801132,900\n",
      "40,4,4.776651173213499,1000\n",
      "20,8,8.121687287754932,500\n",
      "32,4,4.799771723750573,400\n",
      "10,3,3.9278479610082973,100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# target \n",
    "# Transform the DataFrame as requested\n",
    "\n",
    "df_transformed = df_random.copy()\n",
    "\n",
    "# col1 as the multiplication of col1 and col4\n",
    "df_transformed['col1'] = df_transformed['col1'] * df_transformed['col4']\n",
    "\n",
    "# col2 as col3 truncated to the nearest integer\n",
    "df_transformed['col2'] = df_transformed['col3'].astype(int)\n",
    "\n",
    "# col4 multiplied by 100\n",
    "df_transformed['col4'] = df_transformed['col4'] * 100\n",
    "\n",
    "# Remove col5\n",
    "df_transformed.drop('col5', axis=1, inplace=True)\n",
    "\n",
    "df_transformed\n",
    "\n",
    "df_str = df_transformed.to_csv(index=False)\n",
    "print(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+---------+--------+--------+\n",
      "|    |   col1 |   col2 |    col3 |   col4 |   col5 |\n",
      "|----+--------+--------+---------+--------+--------|\n",
      "|  0 |      6 |      4 | 0.56713 |     10 |      4 |\n",
      "|  1 |      1 |      6 | 2.72656 |      9 |      6 |\n",
      "|  2 |      4 |      3 | 4.77665 |     10 |      1 |\n",
      "|  3 |      4 |      5 | 8.12169 |      5 |      3 |\n",
      "|  4 |      8 |      8 | 4.79977 |      4 |      4 |\n",
      "|  5 |     10 |      7 | 3.92785 |      1 |      9 |\n",
      "+----+--------+--------+---------+--------+--------+\n",
      "+----+--------+--------+---------+--------+\n",
      "|    |   col1 |   col2 |    col3 |   col4 |\n",
      "|----+--------+--------+---------+--------|\n",
      "|  0 |     60 |      0 | 0.56713 |   1000 |\n",
      "|  1 |      9 |      2 | 2.72656 |    900 |\n",
      "|  2 |     40 |      4 | 4.77665 |   1000 |\n",
      "|  3 |     20 |      8 | 8.12169 |    500 |\n",
      "|  4 |     32 |      4 | 4.79977 |    400 |\n",
      "|  5 |     10 |      3 | 3.92785 |    100 |\n",
      "+----+--------+--------+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#get the text form of each dataframe\n",
    "txt = tabulate(df_random, headers = 'keys', tablefmt = 'psql')\n",
    "txt_new = tabulate(df_transformed, headers = 'keys', tablefmt = 'psql')\n",
    "print(txt)\n",
    "print(txt_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Original dataset\n",
    "data = \"\"\"\n",
    "col1,col2,col3,col4,col5\n",
    "6,4,0.5671297731744318,10,4\n",
    "1,6,2.726562945801132,9,6\n",
    "4,3,4.776651173213499,10,1\n",
    "4,5,8.121687287754932,5,3\n",
    "8,8,4.799771723750573,4,4\n",
    "10,7,3.9278479610082973,1,9\n",
    "\"\"\"\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = pd.read_csv(StringIO(data))\n",
    "def transform_df(df):\n",
    "    df_transformed = df.copy()\n",
    "\n",
    "    # col1 as the multiplication of col1 and col4\n",
    "    df_transformed['col1'] = df['col1'] * df['col4']\n",
    "\n",
    "    # col2 as col3 truncated to the nearest integer\n",
    "    df_transformed['col2'] = df['col3'].astype(int)\n",
    "\n",
    "    # col4 multiplied by 100\n",
    "    df_transformed['col4'] = df['col4'] * 100\n",
    "\n",
    "    # Remove col5\n",
    "    df_transformed.drop('col5', axis=1, inplace=True)\n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "col1,col2,col3,col4,col5\n",
    "6,4,0.5671297731744318,10,4\n",
    "1,6,2.726562945801132,9,6\n",
    "4,3,4.776651173213499,10,1\n",
    "4,5,8.121687287754932,5,3\n",
    "8,8,4.799771723750573,4,4\n",
    "10,7,3.9278479610082973,1,9\n",
    "\"\"\"\n",
    "df = pd.read_csv(StringIO(data))\n",
    "new_data_testing = \"\"\"\n",
    "col1,col2,col3,col4\n",
    "60,0,0.5671297731744318,1000\n",
    "9,2,2.726562945801132,900\n",
    "40,4,4.776651173213499,1000\n",
    "20,8,8.121687287754932,500\n",
    "32,4,4.799771723750573,400\n",
    "10,3,3.9278479610082973,100\n",
    "\"\"\"\n",
    "def evaluate_correctness(target_df, input_df):\n",
    "    score = 0\n",
    "    for col in target_df.columns:\n",
    "        if col not in input_df.columns:\n",
    "            score -=1 \n",
    "        else:\n",
    "            if np.all(target_df[col] != input_df[col]):\n",
    "                score-=1\n",
    "    for col in input_df.columns:\n",
    "        if col not in target_df.columns:\n",
    "            score -=1\n",
    "    return score\n",
    "new_data_df_testing = pd.read_csv(StringIO(new_data_testing))\n",
    "assert evaluate_correctness(new_data_df_testing, transform_df(df)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1,col2,col3,col4,col5\n",
      "6,1,5.3881673400335695,3,2\n",
      "9,2,4.191945144032948,5,8\n",
      "10,8,6.852195003967595,8,1\n",
      "6,7,2.0445224973151745,8,7\n",
      "1,10,8.781174363909454,10,10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Define the number of rows\n",
    "n_rows = 5\n",
    "\n",
    "# Create the DataFrame with random data\n",
    "np.random.seed(1)  # Set seed for reproducibility\n",
    "df_random = pd.DataFrame({\n",
    "    'col1': np.random.randint(1, 11, size=n_rows),\n",
    "    'col2': np.random.randint(1, 11, size=n_rows),\n",
    "    'col3': np.random.uniform(0, 10, size=n_rows),\n",
    "    'col4': np.random.randint(1, 11, size=n_rows),\n",
    "    'col5': np.random.randint(1, 11, size=n_rows)\n",
    "})\n",
    "# remove index column\n",
    "df_random.index.name = None\n",
    "\n",
    "df_str = df_random.to_csv(index=False)\n",
    "print(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1,col2,col3\n",
      "6,2,8.388167340033569\n",
      "15,3,9.191945144032948\n",
      "25,9,14.852195003967594\n",
      "31,8,10.044522497315175\n",
      "32,11,18.781174363909454\n",
      "0,0,0.0\n",
      "0,0,0.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6902/1912676192.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transformed_requested = df_transformed_requested.append(pd.DataFrame([[0,0,0]], columns=df_transformed_requested.columns))\n",
      "/tmp/ipykernel_6902/1912676192.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transformed_requested = df_transformed_requested.append(pd.DataFrame([[0,0,0]], columns=df_transformed_requested.columns))\n"
     ]
    }
   ],
   "source": [
    "def transform_df(df):\n",
    "    df_transformed_requested = df.copy()\n",
    "    df_transformed_requested['col1'] = df['col1'].cumsum()\n",
    "\n",
    "    # col2 + 1\n",
    "    df_transformed_requested['col2'] = df['col2'] + 1\n",
    "\n",
    "    # col3 plus col4\n",
    "    df_transformed_requested['col3'] = df['col3'] + df['col4']\n",
    "\n",
    "    # Remove col4 and col5\n",
    "    df_transformed_requested.drop(['col4', 'col5'], axis=1, inplace=True)\n",
    "\n",
    "    # add two extra rows that are all zeros to the df\n",
    "    df_transformed_requested = df_transformed_requested.append(pd.DataFrame([[0,0,0]], columns=df_transformed_requested.columns))\n",
    "    df_transformed_requested = df_transformed_requested.append(pd.DataFrame([[0,0,0]], columns=df_transformed_requested.columns))\n",
    "    return df_transformed_requested\n",
    "transformed_df = transform_df(df_random)\n",
    "df_str = transformed_df.to_csv(index=False)\n",
    "print(df_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------+---------+--------+--------+\n",
      "|    |   col1 |   col2 |    col3 |   col4 |   col5 |\n",
      "|----+--------+--------+---------+--------+--------|\n",
      "|  0 |      6 |      1 | 5.38817 |      3 |      2 |\n",
      "|  1 |      9 |      2 | 4.19195 |      5 |      8 |\n",
      "|  2 |     10 |      8 | 6.8522  |      8 |      1 |\n",
      "|  3 |      6 |      7 | 2.04452 |      8 |      7 |\n",
      "|  4 |      1 |     10 | 8.78117 |     10 |     10 |\n",
      "+----+--------+--------+---------+--------+--------+\n",
      "+----+--------+--------+----------+\n",
      "|    |   col1 |   col2 |     col3 |\n",
      "|----+--------+--------+----------|\n",
      "|  0 |      6 |      2 |  8.38817 |\n",
      "|  1 |     15 |      3 |  9.19195 |\n",
      "|  2 |     25 |      9 | 14.8522  |\n",
      "|  3 |     31 |      8 | 10.0445  |\n",
      "|  4 |     32 |     11 | 18.7812  |\n",
      "|  0 |      0 |      0 |  0       |\n",
      "|  0 |      0 |      0 |  0       |\n",
      "+----+--------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "#get the text form of each dataframe\n",
    "txt = tabulate(df_random, headers = 'keys', tablefmt = 'psql')\n",
    "txt_new = tabulate(transformed_df, headers = 'keys', tablefmt = 'psql')\n",
    "print(txt)\n",
    "print(txt_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6902/1912676192.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transformed_requested = df_transformed_requested.append(pd.DataFrame([[0,0,0]], columns=df_transformed_requested.columns))\n",
      "/tmp/ipykernel_6902/1912676192.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_transformed_requested = df_transformed_requested.append(pd.DataFrame([[0,0,0]], columns=df_transformed_requested.columns))\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"\n",
    "col1,col2,col3,col4,col5\n",
    "6,1,5.3881673400335695,3,2\n",
    "9,2,4.191945144032948,5,8\n",
    "10,8,6.852195003967595,8,1\n",
    "6,7,2.0445224973151745,8,7\n",
    "1,10,8.781174363909454,10,10\n",
    "\"\"\"\n",
    "df = pd.read_csv(StringIO(data))\n",
    "new_data_testing = \"\"\"\n",
    "col1,col2,col3\n",
    "6,2,8.388167340033569\n",
    "15,3,9.191945144032948\n",
    "25,9,14.852195003967594\n",
    "31,8,10.044522497315175\n",
    "32,11,18.781174363909454\n",
    "0,0,0.0\n",
    "0,0,0.0\n",
    "\"\"\"\n",
    "def evaluate_correctness(target_df, input_df):\n",
    "    # drop index column from both\n",
    "    target_df.reset_index(drop=True, inplace=True)\n",
    "    input_df.reset_index(drop=True, inplace=True)\n",
    "    score = 0\n",
    "    for col in target_df.columns:\n",
    "        if col not in input_df.columns:\n",
    "            score -=1 \n",
    "        else:\n",
    "            if np.all(target_df[col] != input_df[col]):\n",
    "                score-=1\n",
    "    for col in input_df.columns:\n",
    "        if col not in target_df.columns:\n",
    "            score -=1\n",
    "    return score\n",
    "new_data_df_testing = pd.read_csv(StringIO(new_data_testing))\n",
    "assert evaluate_correctness(new_data_df_testing, transform_df(df)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editing Augment Fix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Calculator:\n",
    "    def __init__(self):\n",
    "        # the calculator only keeps track of the current number\n",
    "        self.current_number = 0\n",
    "        # stores the previous operations performed\n",
    "        self.previous_operations = []\n",
    "    def add(self, a):\n",
    "        '''\n",
    "        a: real number\n",
    "        '''\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"add\"))\n",
    "        self.current_number += a + 20\n",
    "    \n",
    "    def subtract(self, a):\n",
    "        '''\n",
    "        a: real number\n",
    "        '''\n",
    "\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"subtract\"))\n",
    "        self.current_number =  self.current_number - a/10\n",
    "\n",
    "    def multiply(self, a):\n",
    "        '''\n",
    "        a: real number\n",
    "        '''\n",
    "\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"multiply\"))\n",
    "        self.current_number =  (self.current_number ** a ) / a\n",
    "\n",
    "    def divide(self, a):\n",
    "        '''\n",
    "        a: positive integer\n",
    "        '''\n",
    "\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"divide\"))\n",
    "        self.current_number =  self.current_number / a * 2\n",
    "\n",
    "    def undo_last_operation(self):\n",
    "        '''\n",
    "        undoes the last operation performed and restors current_number to the value before the last operation\n",
    "        '''\n",
    "        last_operation = self.previous_operations.pop()\n",
    "    \n",
    "    def undo_last_k_operations(self, k):\n",
    "        ''' \n",
    "        undoes the last k operations performed and restores current_number to the value before the last k operations\n",
    "        Args:\n",
    "            k (int): number of operations to undo\n",
    "        '''\n",
    "        for i in range(k):\n",
    "            self.undo_last_operation()\n",
    "          \n",
    "'''\n",
    "This is a special calculator that keeps track of the previous operations performed.\n",
    "Note that the operations like add are not the standard ones\n",
    "\n",
    "Your job is to fix some remaining bugs in the calculator class:\n",
    "- you should not modify the behavior add, subtract, multiply, divide methods in terms of the calculation\n",
    "- make sure that the add, subtract, multiply, divide methods only execute if the input is valid, if the input is not valid, the method should return without doing anything or raising errors\n",
    "- fix the implementation of undo_last_operation by relying on the previous_operations list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis is a special calculator that keeps track of the previous operations performed.\\nNote that the operations like add are not the standard ones\\n\\nYour job is to fix some remaining bugs in the calculator class:\\n- you should not modify the behavior add, subtract, multiply, divide methods in terms of the calculation\\n- make sure that the add, subtract, multiply, divide methods only execute if the input is valid, if the input is not valid, the method should return without doing anything or raising errors\\n- fix the implementation of undo_last_operation by relying on the previous_operations list\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Calculator:\n",
    "    def __init__(self):\n",
    "        # the calculator only keeps track of the current number\n",
    "        self.current_number = 0\n",
    "        # stores the previous operations performed\n",
    "        self.previous_operations = []\n",
    "\n",
    "\n",
    "    def add(self, a):\n",
    "        '''\n",
    "        a: real number\n",
    "        '''\n",
    "        if not isinstance(a, (int, float)):\n",
    "            return\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"add\"))\n",
    "        self.current_number += a + 20\n",
    "    \n",
    "    def subtract(self, a):\n",
    "        '''\n",
    "        a: real number\n",
    "        '''\n",
    "        if not isinstance(a, (int, float)):\n",
    "            return\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"subtract\"))\n",
    "        self.current_number =  self.current_number - a/10\n",
    "\n",
    "    def multiply(self, a):\n",
    "        '''\n",
    "        a: real number\n",
    "        '''\n",
    "        if not isinstance(a, (int, float)) or a == 0:\n",
    "            return\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"multiply\"))\n",
    "        self.current_number =  (self.current_number ** a ) / a\n",
    "\n",
    "    def divide(self, a):\n",
    "        '''\n",
    "        a: positive integer\n",
    "        '''\n",
    "        if not isinstance(a, (int)) or a <= 0:\n",
    "            return\n",
    "        # two lines below should not be changed\n",
    "        self.previous_operations.append((a, \"divide\"))\n",
    "        self.current_number =  self.current_number / a * 2\n",
    "\n",
    "    def undo_last_operation(self):\n",
    "        '''\n",
    "        undoes the last operation performed and restors current_number to the value before the last operation\n",
    "        '''\n",
    "        last_operation = self.previous_operations.pop()\n",
    "        if last_operation[1] == \"add\":\n",
    "            self.current_number -= last_operation[0] + 20\n",
    "        elif last_operation[1] == \"subtract\":\n",
    "            self.current_number += last_operation[0]/10\n",
    "        elif last_operation[1] == \"multiply\":\n",
    "            self.current_number =  (self.current_number * last_operation[0] ) ** (1/last_operation[0])\n",
    "        elif last_operation[1] == \"divide\":\n",
    "            self.current_number =  self.current_number * last_operation[0] / 2\n",
    "        \n",
    "    \n",
    "    def undo_last_k_operations(self, k):\n",
    "        ''' \n",
    "        undoes the last k operations performed and restores current_number to the value before the last k operations\n",
    "        Args:\n",
    "            k (int): number of operations to undo\n",
    "        '''\n",
    "        for i in range(k):\n",
    "            self.undo_last_operation()\n",
    "          \n",
    "'''\n",
    "This is a special calculator that keeps track of the previous operations performed.\n",
    "Note that the operations like add are not the standard ones\n",
    "\n",
    "Your job is to fix some remaining bugs in the calculator class:\n",
    "- you should not modify the behavior add, subtract, multiply, divide methods in terms of the calculation\n",
    "- make sure that the add, subtract, multiply, divide methods only execute if the input is valid, if the input is not valid, the method should return without doing anything or raising errors\n",
    "- fix the implementation of undo_last_operation by relying on the previous_operations list\n",
    "- do not rename any of the existing methods or variable names\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "24.78\n",
      "24.78\n",
      "307.0242\n",
      "307.0242\n",
      "24.78\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "calc = Calculator()\n",
    "calc.add(5)\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 25\n",
    "calc.add('a')\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 25\n",
    "calc.subtract(2.2)\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 24.78\n",
    "calc.multiply(0)\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 24.78\n",
    "calc.multiply(2)\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 307.0242\n",
    "calc.divide(-1)\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 307.0242\n",
    "calc.undo_last_operation()\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 24.78\n",
    "calc.undo_last_k_operations(2)\n",
    "print(calc.current_number)\n",
    "assert calc.current_number == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, max_vocab_size=200):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.word_to_id = {}\n",
    "        self.id_to_word = {}\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # Split text into words by spaces\n",
    "        return text.lower().split()\n",
    "\n",
    "    def build_vocabulary(self, corpus):\n",
    "        # to be implemented\n",
    "        # Flatten the list of sentences into a list of words\n",
    "        all_words = [word for sentence in corpus for word in self.tokenize(sentence)]\n",
    "\n",
    "        # Count the frequency of each word\n",
    "        word_freq = Counter(all_words)\n",
    "\n",
    "        # Select the top 'max_vocab_size' words\n",
    "        most_common_words = word_freq.most_common(self.max_vocab_size)\n",
    "\n",
    "        # Assign an ID to each word\n",
    "        self.word_to_id = {word: idx for idx, (word, _) in enumerate(most_common_words)}\n",
    "        self.id_to_word = {idx: word for word, idx in self.word_to_id.items()}\n",
    "\n",
    "    def get_word_id(self, word):\n",
    "        # Retrieve the ID of a word, return None if the word is not in the vocabulary\n",
    "        return self.word_to_id.get(word)\n",
    "\n",
    "    def get_word_by_id(self, word_id):\n",
    "        # Retrieve a word by its ID, return None if the ID is not in the vocabulary\n",
    "        return self.id_to_word.get(word_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Your goal is to implement the  build_vocabulary method in the Tokenizer class provided. \n",
    "A tokenizer is an object that converts words to numerical IDs.\n",
    "\n",
    "Objective of build_vocabulary Method:\n",
    "\n",
    "The method's primary goal is to create two dictionaries: self.word_to_id and self.id_to_word.\n",
    "self.word_to_id should map each unique word in your corpus to a unique numerical identifier (ID).\n",
    "self.id_to_word is the reverse mapping, where each unique ID corresponds to a word.\n",
    "The method should only consider the most frequent words in the corpus, up to a limit specified by max_vocab_size.\n",
    "'''\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self, max_vocab_size=200):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.word_to_id = {}\n",
    "        self.id_to_word = {}\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # do not change\n",
    "        # Split text into words by spaces\n",
    "        return text.lower().split()\n",
    "\n",
    "    def build_vocabulary(self, corpus):\n",
    "        '''\n",
    "        corpus: a list of strings (string denotes a sentence composed of words seperated by spaces)\n",
    "        '''\n",
    "        # WRITE CODE HERE\n",
    "        return \n",
    "    \n",
    "\n",
    "    def get_word_id(self, word):\n",
    "        # do not change\n",
    "        # Retrieve the ID of a word, return None if the word is not in the vocabulary\n",
    "        return self.word_to_id.get(word)\n",
    "\n",
    "    def get_word_by_id(self, word_id):\n",
    "        # do not change\n",
    "        # Retrieve a word by its ID, return None if the ID is not in the vocabulary\n",
    "        return self.id_to_word.get(word_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "'hello' should be in the vocabulary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Run the tests\u001b[39;00m\n\u001b[1;32m     28\u001b[0m test_tokenize()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtest_build_vocabulary_and_get_word_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m test_get_word_by_id()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll tests passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mtest_build_vocabulary_and_get_word_id\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m corpus \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello world\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello python\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello world\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mbuild_vocabulary(corpus)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mget_word_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be in the vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mget_word_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworld\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworld\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be in the vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mget_word_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should not be in the vocabulary due to max_vocab_size limit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 'hello' should be in the vocabulary"
     ]
    }
   ],
   "source": [
    "def test_tokenize():\n",
    "    tokenizer = Tokenizer()\n",
    "    assert tokenizer.tokenize(\"Hello world\") == [\"hello\", \"world\"], \"Tokenization failed\"\n",
    "\n",
    "def test_build_vocabulary_and_get_word_id():\n",
    "    tokenizer = Tokenizer(max_vocab_size=2)\n",
    "    corpus = [\"hello world\", \"hello python\", \"hello world\"]\n",
    "    tokenizer.build_vocabulary(corpus)\n",
    "    \n",
    "    assert tokenizer.get_word_id(\"hello\") is not None, \"'hello' should be in the vocabulary\"\n",
    "    assert tokenizer.get_word_id(\"world\") is not None, \"'world' should be in the vocabulary\"\n",
    "    assert tokenizer.get_word_id(\"python\") is None, \"'python' should not be in the vocabulary due to max_vocab_size limit\"\n",
    "\n",
    "def test_get_word_by_id():\n",
    "    tokenizer = Tokenizer(max_vocab_size=2)\n",
    "    corpus = [\"apple orange\", \"banana apple\", \"cherry banana\"]\n",
    "    tokenizer.build_vocabulary(corpus)\n",
    "    \n",
    "    apple_id = tokenizer.get_word_id(\"apple\")\n",
    "    assert tokenizer.get_word_by_id(apple_id) == \"apple\", \"ID lookup for 'apple' failed\"\n",
    "\n",
    "    # Assuming 'cherry' is not in the top 2 words and therefore has no ID\n",
    "    cherry_id = tokenizer.get_word_id(\"cherry\")\n",
    "    assert cherry_id is None, \"'cherry' should not have an ID\"\n",
    "    assert tokenizer.get_word_by_id(cherry_id) is None, \"ID lookup for a non-existent word should return None\"\n",
    "\n",
    "# Run the tests\n",
    "test_tokenize()\n",
    "test_build_vocabulary_and_get_word_id()\n",
    "test_get_word_by_id()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login authenticator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "class LoginAuthenticator:\n",
    "    def __init__(self):\n",
    "        self.user_credentials = {}  # dictionary for username: hashed_password\n",
    "\n",
    "    def _hash_password(self, password):\n",
    "        \"\"\"Helper method to hash a password.\"\"\"\n",
    "        return hashlib.sha256(password.encode()).hexdigest()\n",
    "\n",
    "    def add_user(self, username, password):\n",
    "        \"\"\"Adds a new user if the username doesn't already exist.\"\"\"\n",
    "        if username in self.user_credentials:\n",
    "            return False  # Username already exists\n",
    "        self.user_credentials[username] = self._hash_password(password)\n",
    "        return True\n",
    "\n",
    "    def authenticate_user(self, username, password):\n",
    "        \"\"\"Checks if the given username and password are valid.\"\"\"\n",
    "        if username not in self.user_credentials:\n",
    "            return False\n",
    "        return self.user_credentials[username] == self._hash_password(password)\n",
    "\n",
    "    def remove_user(self, username):\n",
    "        \"\"\"Removes a user from the system.\"\"\"\n",
    "        if username in self.user_credentials:\n",
    "            del self.user_credentials[username]\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def change_password(self, username, old_password, new_password):\n",
    "        \"\"\"Changes the password for a user if the old password is correct.\"\"\"\n",
    "        if self.authenticate_user(username, old_password):\n",
    "            self.user_credentials[username] = self._hash_password(new_password)\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to implement the LoginAuthenticator class. This class will be used to authenticate users of a system. \n",
    "\n",
    "To implement the methods of the LoginAuthenticator class, follow these instructions for each method:\n",
    "\n",
    "_hash_password (Private Method):\n",
    "\n",
    "Purpose: To create a hash of a given password.\n",
    "Parameters: password (string).\n",
    "Process: use any hashing tehnique you like\n",
    "Return: The hashed password \n",
    "\n",
    "add_user Method:\n",
    "Purpose: To add a new user to the system with a username and a password.\n",
    "Parameters: username (string), password (string).\n",
    "Process:\n",
    "Check if the username already exists in self.user_credentials.\n",
    "If it does, return False to indicate the username is already taken.\n",
    "If not, hash the password using _hash_password method and store the username and hashed password in self.user_credentials.\n",
    "Return: True if the user was successfully added, otherwise False.\n",
    "\n",
    "remove_user Method:\n",
    "\n",
    "Purpose: To remove a user from the system.\n",
    "Parameters: username (string).\n",
    "Process:\n",
    "Check if the username exists in self.user_credentials.\n",
    "If it does, delete the username entry from self.user_credentials.\n",
    "Return: True if the user was successfully removed, otherwise False.\n",
    "\n",
    "\n",
    "change_password Method:\n",
    "\n",
    "Purpose: To change a user's password.\n",
    "Parameters: username (string), old_password (string), new_password (string).\n",
    "Process:\n",
    "First, authenticate the user using the authenticate_user method with username and old_password.\n",
    "If authentication is successful, hash the new_password and update the self.user_credentials with the new hashed password.\n",
    "Return: True if the password was successfully changed, otherwise False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LoginAuthenticator:\n",
    "    def __init__(self):\n",
    "        # DO NOT CHANGE\n",
    "        self.user_credentials = {}  # dictionary for username: hashed_password\n",
    "\n",
    "    def _hash_password(self, password):\n",
    "        # WRITE CODE HERE\n",
    "        return\n",
    "\n",
    "    def add_user(self, username, password):\n",
    "        # WRITE CODE HERE\n",
    "        return\n",
    "\n",
    "    def authenticate_user(self, username, password):\n",
    "        # DO NOT CHANGE\n",
    "        \"\"\"Checks if the given username and password are valid.\"\"\"\n",
    "        if username not in self.user_credentials:\n",
    "            return False\n",
    "        return self.user_credentials[username] == self._hash_password(password)\n",
    "\n",
    "    def remove_user(self, username):\n",
    "        # WRITE CODE HERE\n",
    "        return\n",
    "\n",
    "    def change_password(self, username, old_password, new_password):\n",
    "        # WRITE CODE HERE\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m authenticator \u001b[38;5;241m=\u001b[39m LoginAuthenticator()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Test adding new users\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m authenticator\u001b[38;5;241m.\u001b[39madd_user(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Should succeed\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m authenticator\u001b[38;5;241m.\u001b[39madd_user(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword2\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Should succeed\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m authenticator\u001b[38;5;241m.\u001b[39madd_user(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_password\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# Should fail, user1 already exists\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assuming the LoginAuthenticator class is defined as previously provided\n",
    "\n",
    "# Create an instance of the LoginAuthenticator\n",
    "authenticator = LoginAuthenticator()\n",
    "\n",
    "# Test adding new users\n",
    "assert authenticator.add_user(\"user1\", \"password1\") == True  # Should succeed\n",
    "assert authenticator.add_user(\"user2\", \"password2\") == True  # Should succeed\n",
    "assert authenticator.add_user(\"user1\", \"new_password\") == False  # Should fail, user1 already exists\n",
    "\n",
    "# Test authenticating users\n",
    "assert authenticator.authenticate_user(\"user1\", \"password1\") == True  # Correct credentials\n",
    "assert authenticator.authenticate_user(\"user1\", \"wrong_password\") == False  # Wrong password\n",
    "assert authenticator.authenticate_user(\"user3\", \"password\") == False  # Non-existent user\n",
    "\n",
    "# Test removing users\n",
    "assert authenticator.remove_user(\"user1\") == True  # Should succeed in removing user1\n",
    "assert authenticator.remove_user(\"user1\") == False  # user1 no longer exists\n",
    "assert authenticator.remove_user(\"user3\") == False  # user3 does not exist\n",
    "\n",
    "# Test changing passwords\n",
    "assert authenticator.change_password(\"user2\", \"password2\", \"newpass2\") == True  # Should succeed\n",
    "assert authenticator.authenticate_user(\"user2\", \"newpass2\") == True  # New password should work\n",
    "assert authenticator.change_password(\"user2\", \"password2\", \"anothernewpass\") == False  # Old password no longer valid\n",
    "assert authenticator.change_password(\"nonexistent_user\", \"pass\", \"newpass\") == False  # Non-existent user\n",
    "\n",
    "print(\"All tests passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to complete the function simplified_t_test. This function takes as input two arrays of numbers and will return a float value called t_test. \n",
    "\n",
    "The simplified_t_test is a statistical test that is used to compare the means of two populations. The value is computed as follows:\n",
    "\n",
    "t_test =  abs ( (mean1 - mean2) / sqrt((variance1 / n1) + (variance2 / n2))  )\n",
    "\n",
    "where mean1 and mean2 are the means of the two populations, variance1 and variance2 are the variances of the two populations with a modified denominator:\n",
    "variance1 = sum((x - mean1)^2) / (n1 - 2)\n",
    "variance2 = sum((x - mean2)^2) / (n2 - 2)\n",
    "\n",
    ", and n1 and n2 are the number of samples in each population. Note this is not the ordinary t-test, but a simplified version of it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function signature\n",
    "def simplified_t_test(sample1, sample2):\n",
    "    \"\"\"\n",
    "    :param sample1: List or array of sample data (sample 1)\n",
    "    :param sample2: List or array of sample data (sample 2)\n",
    "    :return: simplified t-test statistic\n",
    "    \"\"\"\n",
    "    t_test = 0\n",
    "    # write your code here\n",
    "    return t_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function signature\n",
    "import numpy as np\n",
    "\n",
    "def simplified_t_test(sample1, sample2):\n",
    "    \"\"\"\n",
    "    :param sample1: List or array of sample data (sample 1)\n",
    "    :param sample2: List or array of sample data (sample 2)\n",
    "    :return: simplified t-test statistic\n",
    "    \"\"\"\n",
    "    t_test = 0\n",
    "    # write your code here\n",
    "    mean1 = np.mean(sample1)\n",
    "    mean2 = np.mean(sample2)\n",
    "    # variance with modified denominator\n",
    "    variance1 = np.var(sample1, ddof=2)\n",
    "    variance2 = np.var(sample2, ddof=2)\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    t_test = (mean1 - mean2) / np.sqrt(variance1/n1 + variance2/n2)\n",
    "    return abs(t_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-2.0, pvalue=0.08051623795726257)\n",
      "1.7320508075688774\n",
      "Ttest_indResult(statistic=-2.0, pvalue=0.08051623795726257)\n",
      "Ttest_indResult(statistic=0.0, pvalue=1.0)\n",
      "Ttest_indResult(statistic=-0.40451991747794513, pvalue=0.6975372096030519)\n",
      "0.35032452487268523\n",
      "Ttest_indResult(statistic=-0.40451991747794513, pvalue=0.6975372096030519)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test with known values\n",
    "sample1 = [10, 20, 30, 40, 50]\n",
    "sample2 = [30, 40, 50, 60, 70]\n",
    "expected_t_stat = 1.7320508075688774  # This value should be pre-calculated\n",
    "print(simplified_t_test(sample1, sample2))\n",
    "assert np.isclose(simplified_t_test(sample1, sample2), expected_t_stat, atol=1e-3), \"Test with known values failed\"\n",
    "\n",
    "# Test with identical samples\n",
    "identical_sample = [1, 2, 3, 4, 5]\n",
    "assert simplified_t_test(identical_sample, identical_sample) == 0, \"Test with identical samples failed\"\n",
    "\n",
    "\n",
    "sample1 = [1,2,-1,3,4]\n",
    "sample2 = [2,3,-2,4,5]\n",
    "expected_t_stat = 0.35032452487268523\n",
    "print(simplified_t_test(sample1, sample2))\n",
    "assert np.isclose(simplified_t_test(sample1, sample2), expected_t_stat, atol=1e-3), \"Test with known values failed\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to create a class called Retriever. This class will be used to retrieve similar vectors from a collection of vectors. You should follow the instructions below to complete this task.\n",
    "\n",
    "\n",
    "Create an instance of the Retriever class by providing two arguments:\n",
    "vectors: A numpy array of vectors you want to analyze.\n",
    "k: An integer indicating the number of top similar vectors you want to retrieve.\n",
    "Example:\n",
    "\n",
    "from numpy import array\n",
    "vectors = array([[1, 2], [3, 4], [5, 6]])\n",
    "k = 2\n",
    "retriever = Retriever(vectors, k)\n",
    "\n",
    "\n",
    "Setting 'k' Value:\n",
    "\n",
    "Use the set_k method to update the value of k (number of top vectors to retrieve).\n",
    "This method takes a single integer argument.\n",
    "The value of k should be between 1 and the total number of vectors. If not, then the method should do nothing (do not raise an error).\n",
    "Example:\n",
    "retriever.set_k(3)\n",
    "\n",
    "Adding New Vectors:\n",
    "\n",
    "Add additional vectors to your existing collection using the add_vectors method.\n",
    "This method accepts a numpy array of new vectors to be added.\n",
    "Example:\n",
    "\n",
    "new_vectors = array([[7, 8], [9, 10]])\n",
    "retriever.add_vectors(new_vectors)\n",
    "\n",
    "\n",
    "Calculating Distances:\n",
    "\n",
    "To calculate the distance between a query vector and all stored vectors, use the distance method.\n",
    "This method takes a single numpy array representing the query vector.\n",
    "It returns a numpy array of distances.\n",
    "Example:\n",
    "\n",
    "\n",
    "query_vector = array([1, 2])\n",
    "distances = retriever.distance(query_vector)\n",
    "\n",
    "\n",
    "Retrieving Top 'k' Similar Vectors:\n",
    "\n",
    "Use the get_top_k_similar_vectors method to find the top 'k' vectors most similar to a given query vector.\n",
    "This method takes a single numpy array as the query vector.\n",
    "It returns a numpy array of the top 'k' similar vectors.\n",
    "\n",
    "Example:\n",
    "\n",
    "top_vectors = retriever.get_top_k_similar_vectors(query_vector)\n",
    "\n",
    "Generating a Similarity Matrix:\n",
    "\n",
    "To create a similarity matrix between multiple queries and the stored vectors, use the get_similarity_matrix method.\n",
    "This method accepts a numpy array of query vectors.\n",
    "It returns a 2D numpy array where each row corresponds to the distances between a query vector and all stored vectors.\n",
    "\n",
    "Example:\n",
    "\n",
    "query_vectors = array([[1, 2], [3, 4]])\n",
    "similarity_matrix = retriever.get_similarity_matrix(query_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "class Retriever:\n",
    "    def __init__(self, vectors, k):\n",
    "        self.vectors = vectors\n",
    "        self.k = k\n",
    "\n",
    "    def set_k(self, k):\n",
    "        if k > len(self.vectors) or k < 1:\n",
    "            return\n",
    "        self.k = k\n",
    "\n",
    "    def add_vectors(self, new_vectors):\n",
    "        self.vectors = np.concatenate((self.vectors, new_vectors))\n",
    "        \n",
    "    def distance(self, query):\n",
    "        ''' \n",
    "        query: single numpy arrray\n",
    "        return: inverse l2 distances from query to the vectors\n",
    "        '''\n",
    "        distances = np.linalg.norm(self.vectors - query, axis=1)\n",
    "        return distances\n",
    "    \n",
    "    def get_top_k_similar_vectors(self, query):\n",
    "        '''\n",
    "        query: single numpy array\n",
    "        return: top k similar vectors\n",
    "        '''\n",
    "        scores = self.distance(query)\n",
    "        # np.argsort sorts in ascending order\n",
    "        indices_top = np.argsort(scores)\n",
    "        top_k_indices = indices_top[:self.k]\n",
    "        return self.vectors[top_k_indices]\n",
    "    \n",
    "    def get_similarity_matrix(self, queries):\n",
    "        '''\n",
    "        queries: numpy array of query vectors\n",
    "        return: similarity matrix of size (len(queries), len(self.vectors))\n",
    "        '''\n",
    "        similarity_matrix = []\n",
    "        for query in queries:\n",
    "            similarity_matrix.append(self.distance(query))\n",
    "        return np.array(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          2.82842712  5.65685425  8.48528137 11.3137085 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Test Initialization\n",
    "vectors = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "k = 2\n",
    "retriever = Retriever(vectors, k)\n",
    "assert (retriever.vectors == vectors).all() and retriever.k == k, \"Initialization Failed\"\n",
    "\n",
    "# Test set_k Method\n",
    "retriever.set_k(1)\n",
    "assert retriever.k == 1, \"set_k Method Failed\"\n",
    "retriever.set_k(0)  # Edge case\n",
    "assert retriever.k == 1, \"set_k Method Failed on Edge Case\"\n",
    "\n",
    "# Test add_vectors Method\n",
    "new_vectors = np.array([[7, 8], [9, 10]])\n",
    "retriever.add_vectors(new_vectors)\n",
    "assert (retriever.vectors == np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])).all(), \"add_vectors Method Failed\"\n",
    "\n",
    "# Test distance Method\n",
    "query = np.array([1, 2])\n",
    "distances = retriever.distance(query)\n",
    "ground_truth_distances = np.array([0, 2.82842712, 5.65685425, 8.48528137, 11.3137085])\n",
    "assert np.allclose(distances, ground_truth_distances, atol=1e-3), \"distance Method Failed\"\n",
    "assert len(distances) == len(retriever.vectors), \"distance Method Failed\"\n",
    "\n",
    "# Test get_top_k_similar_vectors Method\n",
    "top_vectors = retriever.get_top_k_similar_vectors(query)\n",
    "ground_truth_top_vectors = np.array([[1, 2]])\n",
    "assert (top_vectors == ground_truth_top_vectors).all(), \"get_top_k_similar_vectors Method Failed\"\n",
    "assert len(top_vectors) == retriever.k, \"get_top_k_similar_vectors Method Failed\"\n",
    "\n",
    "# Test get_similarity_matrix Method\n",
    "query_vectors = np.array([[1, 2], [3, 4]])\n",
    "similarity_matrix = retriever.get_similarity_matrix(query_vectors)\n",
    "\n",
    "assert similarity_matrix.shape == (len(query_vectors), len(retriever.vectors)), \"get_similarity_matrix Method Failed\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### event scheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Description:\n",
    "\n",
    "Input:\n",
    "\n",
    "You have a list of events.\n",
    "Each event is represented as a tuple (start, end, score).\n",
    "start: The starting hour of the event (an integer between 0 and 10).\n",
    "end: The ending hour of the event (an integer between start and 10).\n",
    "score: The importance score of the event (a positive integer).\n",
    "Constraints:\n",
    "\n",
    "The events can only be scheduled between the hours of 0:00 and 10:00.\n",
    "No two events can overlap. An event with an end time of X cannot overlap with another event with a start time of X.\n",
    "Each event can be scheduled only once.\n",
    "Objective:\n",
    "\n",
    "Your goal is to schedule the events in such a way that the total importance score is maximized.\n",
    "The algorithm should return the maximum total importance score that can be achieved with the given set of events.\n",
    "\n",
    "Example:\n",
    "\n",
    "Suppose you have the following list of events:\n",
    "\n",
    "Event 1: (1, 3, 5)\n",
    "Event 2: (1, 2, 3)\n",
    "Event 3: (2, 3, 4)\n",
    "\n",
    "Best schedule would be to pick Event 2 and Event 3, which would give a total importance score of 7.\n",
    "\n",
    "The algorithm should determine the best way to schedule these events between 0:00 and 10:00 to achieve the highest total importance score, without any overlapping of events.\n",
    "\n",
    "Output: The algorithm should return a single integer, which is the highest total importance score achievable under the given constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_events = [(1, 2, 10), (2,3,5), (1,3,14)]\n",
    "\n",
    "def schedule_events(events):\n",
    "    '''\n",
    "    events is a list of tuples of the form (start_time, end_time, score)\n",
    "    '''\n",
    "    score = 0\n",
    "    # write your code here\n",
    "\n",
    "    return score\n",
    "\n",
    "print(schedule_events(test_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event scheduler\n",
    "\n",
    "def binary_search(events, index):\n",
    "    lo, hi = 0, index - 1\n",
    "    while lo <= hi:\n",
    "        mid = (lo + hi) // 2\n",
    "        if events[mid][1] <= events[index][0]:\n",
    "            if events[mid + 1][1] <= events[index][0]:\n",
    "                lo = mid + 1\n",
    "            else:\n",
    "                return mid\n",
    "        else:\n",
    "            hi = mid - 1\n",
    "    return -1\n",
    "\n",
    "def schedule_events(events):\n",
    "    # Sort the events based on their end time\n",
    "    events.sort(key=lambda x: x[1])\n",
    "\n",
    "    n = len(events)\n",
    "    dp = [0] * n\n",
    "    dp[0] = events[0][2]\n",
    "\n",
    "    for i in range(1, n):\n",
    "        incl_prof = events[i][2]\n",
    "        l = binary_search(events, i)\n",
    "        if l != -1:\n",
    "            incl_prof += dp[l]\n",
    "\n",
    "        dp[i] = max(incl_prof, dp[i - 1])\n",
    "\n",
    "    return dp[n-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases passed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test Case 1: Single event\n",
    "events = [(0, 2, 10)]\n",
    "assert schedule_events(events) == 10, \"Test Case 1 Failed\"\n",
    "\n",
    "# Test Case 2: Two non-overlapping events\n",
    "events = [(0, 2, 10), (2, 4, 15)]\n",
    "assert schedule_events(events) == 25, \"Test Case 2 Failed\"\n",
    "\n",
    "# Test Case 3: Two overlapping events, one with higher score\n",
    "events = [(0, 3, 10), (2, 5, 20)]\n",
    "assert schedule_events(events) == 20, \"Test Case 3 Failed\"\n",
    "\n",
    "# Test Case 4: Multiple events, some overlapping\n",
    "events = [(0, 3, 10), (2, 5, 15), (5, 7, 20)]\n",
    "assert schedule_events(events) == 35, \"Test Case 4 Failed\"\n",
    "\n",
    "# Test Case 5: Events with the same time\n",
    "events = [(1, 4, 10), (1, 4, 15)]\n",
    "assert schedule_events(events) == 15, \"Test Case 5 Failed\"\n",
    "\n",
    "# Test Case 6: Events spread throughout the day\n",
    "events = [(0, 2, 10), (3, 5, 15), (6, 8, 20), (9, 10, 25)]\n",
    "assert schedule_events(events) == 70, \"Test Case 6 Failed\"\n",
    "\n",
    "# Test Case 7: Non-overlapping events with equal score\n",
    "events = [(0, 2, 10), (2, 4, 10), (4, 6, 10)]\n",
    "assert schedule_events(events) == 30, \"Test Case 7 Failed\"\n",
    "\n",
    "# Test Case 8: Overlapping events with varying scores\n",
    "events = [(0, 4, 20), (3, 5, 30), (5, 7, 25)]\n",
    "assert schedule_events(events) == 55, \"Test Case 8 Failed\"\n",
    "\n",
    "# Test Case 9: All events overlapping\n",
    "events = [(1, 3, 10), (2, 4, 15), (2, 5, 20)]\n",
    "assert schedule_events(events) == 20, \"Test Case 9 Failed\"\n",
    "\n",
    "\n",
    "print(\"All test cases passed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define your details\n",
    "name = \"YourName\"\n",
    "task_description = \"\"\"\n",
    "\"\"\"\n",
    "function_signature = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "unit_test = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "solution = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "data_type = \"data_manip\"\n",
    "\n",
    "data = {\n",
    "    'name': name,\n",
    "    'task_description': task_description,\n",
    "    'function_signature': function_signature,\n",
    "    'unit_test': unit_test,\n",
    "    'solution': solution,\n",
    "    'type': data_type\n",
    "}\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(\"tasks/\" + name+'.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define your details\n",
    "name = \"retriever\"\n",
    "task_description = \"\"\"\n",
    "Your task is to create a class called Retriever. This class will be used to retrieve similar vectors from a collection of vectors. You should follow the instructions below to complete this task.\n",
    "\n",
    "\n",
    "Create an instance of the Retriever class by providing two arguments:\n",
    "vectors: A numpy array of vectors you want to analyze.\n",
    "k: An integer indicating the number of top similar vectors you want to retrieve.\n",
    "Example:\n",
    "\n",
    "from numpy import array\n",
    "vectors = array([[1, 2], [3, 4], [5, 6]])\n",
    "k = 2\n",
    "retriever = Retriever(vectors, k)\n",
    "\n",
    "\n",
    "Setting 'k' Value:\n",
    "\n",
    "Use the set_k method to update the value of k (number of top vectors to retrieve).\n",
    "This method takes a single integer argument.\n",
    "The value of k should be between 1 and the total number of vectors. If not, then the method should do nothing (do not raise an error).\n",
    "Example:\n",
    "retriever.set_k(3)\n",
    "\n",
    "Adding New Vectors:\n",
    "\n",
    "Add additional vectors to your existing collection using the add_vectors method.\n",
    "This method accepts a numpy array of new vectors to be added.\n",
    "Example:\n",
    "\n",
    "new_vectors = array([[7, 8], [9, 10]])\n",
    "retriever.add_vectors(new_vectors)\n",
    "\n",
    "\n",
    "Calculating Distances:\n",
    "\n",
    "To calculate the distance between a query vector and all stored vectors, use the distance method.\n",
    "This method takes a single numpy array representing the query vector.\n",
    "It returns a numpy array of distances.\n",
    "Example:\n",
    "\n",
    "\n",
    "query_vector = array([1, 2])\n",
    "distances = retriever.distance(query_vector)\n",
    "\n",
    "\n",
    "Retrieving Top 'k' Similar Vectors:\n",
    "\n",
    "Use the get_top_k_similar_vectors method to find the top 'k' vectors most similar to a given query vector.\n",
    "This method takes a single numpy array as the query vector.\n",
    "It returns a numpy array of the top 'k' similar vectors.\n",
    "\n",
    "Example:\n",
    "\n",
    "top_vectors = retriever.get_top_k_similar_vectors(query_vector)\n",
    "\n",
    "Generating a Similarity Matrix:\n",
    "\n",
    "To create a similarity matrix between multiple queries and the stored vectors, use the get_similarity_matrix method.\n",
    "This method accepts a numpy array of query vectors.\n",
    "It returns a 2D numpy array where each row corresponds to the distances between a query vector and all stored vectors.\n",
    "\n",
    "Example:\n",
    "\n",
    "query_vectors = array([[1, 2], [3, 4]])\n",
    "similarity_matrix = retriever.get_similarity_matrix(query_vectors)\n",
    "\"\"\"\n",
    "function_signature = \"\"\"\n",
    "class Retriever:\n",
    "\"\"\"\n",
    "\n",
    "unit_test = \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Test Initialization\n",
    "vectors = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "k = 2\n",
    "retriever = Retriever(vectors, k)\n",
    "assert (retriever.vectors == vectors).all() and retriever.k == k, \"Initialization Failed\"\n",
    "\n",
    "# Test set_k Method\n",
    "retriever.set_k(1)\n",
    "assert retriever.k == 1, \"set_k Method Failed\"\n",
    "retriever.set_k(0)  # Edge case\n",
    "assert retriever.k == 1, \"set_k Method Failed on Edge Case\"\n",
    "\n",
    "# Test add_vectors Method\n",
    "new_vectors = np.array([[7, 8], [9, 10]])\n",
    "retriever.add_vectors(new_vectors)\n",
    "assert (retriever.vectors == np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])).all(), \"add_vectors Method Failed\"\n",
    "\n",
    "# Test distance Method\n",
    "query = np.array([1, 2])\n",
    "distances = retriever.distance(query)\n",
    "ground_truth_distances = np.array([0, 2.82842712, 5.65685425, 8.48528137, 11.3137085])\n",
    "assert np.allclose(distances, ground_truth_distances, atol=1e-3), \"distance Method Failed\"\n",
    "assert len(distances) == len(retriever.vectors), \"distance Method Failed\"\n",
    "\n",
    "# Test get_top_k_similar_vectors Method\n",
    "top_vectors = retriever.get_top_k_similar_vectors(query)\n",
    "ground_truth_top_vectors = np.array([[1, 2]])\n",
    "assert (top_vectors == ground_truth_top_vectors).all(), \"get_top_k_similar_vectors Method Failed\"\n",
    "assert len(top_vectors) == retriever.k, \"get_top_k_similar_vectors Method Failed\"\n",
    "\n",
    "# Test get_similarity_matrix Method\n",
    "query_vectors = np.array([[1, 2], [3, 4]])\n",
    "similarity_matrix = retriever.get_similarity_matrix(query_vectors)\n",
    "\n",
    "assert similarity_matrix.shape == (len(query_vectors), len(retriever.vectors)), \"get_similarity_matrix Method Failed\"\n",
    "\"\"\"\n",
    "solution = \"\"\"\n",
    "import numpy as np\n",
    "class Retriever:\n",
    "    def __init__(self, vectors, k):\n",
    "        self.vectors = vectors\n",
    "        self.k = k\n",
    "\n",
    "    def set_k(self, k):\n",
    "        if k > len(self.vectors) or k < 1:\n",
    "            return\n",
    "        self.k = k\n",
    "\n",
    "    def add_vectors(self, new_vectors):\n",
    "        self.vectors = np.concatenate((self.vectors, new_vectors))\n",
    "        \n",
    "    def distance(self, query):\n",
    "        ''' \n",
    "        query: single numpy arrray\n",
    "        return: inverse l2 distances from query to the vectors\n",
    "        '''\n",
    "        distances = np.linalg.norm(self.vectors - query, axis=1)\n",
    "        return distances\n",
    "    \n",
    "    def get_top_k_similar_vectors(self, query):\n",
    "        '''\n",
    "        query: single numpy array\n",
    "        return: top k similar vectors\n",
    "        '''\n",
    "        scores = self.distance(query)\n",
    "        # np.argsort sorts in ascending order\n",
    "        indices_top = np.argsort(scores)\n",
    "        top_k_indices = indices_top[:self.k]\n",
    "        return self.vectors[top_k_indices]\n",
    "    \n",
    "    def get_similarity_matrix(self, queries):\n",
    "        '''\n",
    "        queries: numpy array of query vectors\n",
    "        return: similarity matrix of size (len(queries), len(self.vectors))\n",
    "        '''\n",
    "        similarity_matrix = []\n",
    "        for query in queries:\n",
    "            similarity_matrix.append(self.distance(query))\n",
    "        return np.array(similarity_matrix)\n",
    "\"\"\"\n",
    "data_type = \"lengthy_code\"\n",
    "\n",
    "data = {\n",
    "    'name': name,\n",
    "    'task_description': task_description,\n",
    "    'function_signature': function_signature,\n",
    "    'unit_test': unit_test,\n",
    "    'solution': solution,\n",
    "    'type': data_type\n",
    "}\n",
    "\n",
    "# Save the dictionary to a JSON file\n",
    "with open(\"tasks/\" + name+'.json', 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hussein2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
