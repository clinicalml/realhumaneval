{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting together\n",
      "  Downloading together-0.2.10-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 19 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sseclient-py<2.0.0,>=1.7.2\n",
      "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.0\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "\u001b[K     |████████████████████████████████| 381 kB 395 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate<0.10.0,>=0.9.0\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting typer<0.10.0,>=0.9.0\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 365 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3.0.0,>=2.31.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting pydantic-core==2.14.6\n",
      "  Downloading pydantic_core-2.14.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 380 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hussein/miniconda3/envs/hussein2/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->together) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hussein/miniconda3/envs/hussein2/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->together) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hussein/miniconda3/envs/hussein2/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->together) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hussein/miniconda3/envs/hussein2/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->together) (2.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/hussein/miniconda3/envs/hussein2/lib/python3.9/site-packages (from typer<0.10.0,>=0.9.0->together) (8.0.4)\n",
      "Installing collected packages: typing-extensions, pydantic-core, annotated-types, typer, tqdm, tabulate, sseclient-py, requests, pydantic, together\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.3.0\n",
      "    Uninstalling typing-extensions-4.3.0:\n",
      "      Successfully uninstalled typing-extensions-4.3.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.0\n",
      "    Uninstalling tqdm-4.64.0:\n",
      "      Successfully uninstalled tqdm-4.64.0\n",
      "  Attempting uninstall: tabulate\n",
      "    Found existing installation: tabulate 0.8.10\n",
      "    Uninstalling tabulate-0.8.10:\n",
      "      Successfully uninstalled tabulate-0.8.10\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.31.0 requires huggingface-hub<1.0,>=0.14.1, but you have huggingface-hub 0.8.1 which is incompatible.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.0 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.0 which is incompatible.\u001b[0m\n",
      "Successfully installed annotated-types-0.6.0 pydantic-2.5.3 pydantic-core-2.14.6 requests-2.31.0 sseclient-py-1.8.0 tabulate-0.9.0 together-0.2.10 tqdm-4.66.1 typer-0.9.0 typing-extensions-4.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 models available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Austism/chronos-hermes-13b',\n",
       " 'DiscoResearch/DiscoLM-mixtral-8x7b-v2',\n",
       " 'EleutherAI/llemma_7b',\n",
       " 'Gryphe/MythoMax-L2-13b',\n",
       " 'Meta-Llama/Llama-Guard-7b',\n",
       " 'Nexusflow/NexusRaven-V2-13B',\n",
       " 'NousResearch/Nous-Capybara-7B-V1p9',\n",
       " 'NousResearch/Nous-Hermes-2-Yi-34B',\n",
       " 'NousResearch/Nous-Hermes-Llama2-13b',\n",
       " 'NousResearch/Nous-Hermes-Llama2-70b',\n",
       " 'NousResearch/Nous-Hermes-llama-2-7b',\n",
       " 'NumbersStation/nsql-llama-2-7B',\n",
       " 'Open-Orca/Mistral-7B-OpenOrca',\n",
       " 'Phind/Phind-CodeLlama-34B-Python-v1',\n",
       " 'Phind/Phind-CodeLlama-34B-v2',\n",
       " 'SG161222/Realistic_Vision_V3.0_VAE',\n",
       " 'Undi95/ReMM-SLERP-L2-13B',\n",
       " 'Undi95/Toppy-M-7B',\n",
       " 'WizardLM/WizardCoder-15B-V1.0',\n",
       " 'WizardLM/WizardCoder-Python-34B-V1.0',\n",
       " 'WizardLM/WizardLM-13B-V1.2',\n",
       " 'WizardLM/WizardLM-70B-V1.0',\n",
       " 'garage-bAInd/Platypus2-70B-instruct',\n",
       " 'huggyllama/llama-65b',\n",
       " 'lmsys/vicuna-13b-v1.5-16k',\n",
       " 'lmsys/vicuna-13b-v1.5',\n",
       " 'lmsys/vicuna-7b-v1.5',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.1',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       " 'mistralai/Mistral-7B-v0.1',\n",
       " 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
       " 'openchat/openchat-3.5-1210',\n",
       " 'prompthero/openjourney',\n",
       " 'runwayml/stable-diffusion-v1-5',\n",
       " 'stabilityai/stable-diffusion-2-1',\n",
       " 'stabilityai/stable-diffusion-xl-base-1.0',\n",
       " 'teknium/OpenHermes-2-Mistral-7B',\n",
       " 'teknium/OpenHermes-2p5-Mistral-7B',\n",
       " 'togethercomputer/CodeLlama-13b-Instruct',\n",
       " 'togethercomputer/CodeLlama-13b-Python',\n",
       " 'togethercomputer/CodeLlama-13b',\n",
       " 'togethercomputer/CodeLlama-34b-Instruct',\n",
       " 'togethercomputer/CodeLlama-34b-Python',\n",
       " 'togethercomputer/CodeLlama-34b',\n",
       " 'togethercomputer/CodeLlama-7b-Instruct',\n",
       " 'togethercomputer/CodeLlama-7b-Python',\n",
       " 'togethercomputer/CodeLlama-7b',\n",
       " 'togethercomputer/GPT-JT-6B-v1',\n",
       " 'togethercomputer/GPT-JT-Moderation-6B',\n",
       " 'togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
       " 'togethercomputer/LLaMA-2-7B-32K',\n",
       " 'togethercomputer/Llama-2-7B-32K-Instruct',\n",
       " 'togethercomputer/Pythia-Chat-Base-7B-v0.16',\n",
       " 'togethercomputer/Qwen-7B-Chat',\n",
       " 'togethercomputer/Qwen-7B',\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Base',\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Chat',\n",
       " 'togethercomputer/RedPajama-INCITE-7B-Instruct',\n",
       " 'togethercomputer/RedPajama-INCITE-Base-3B-v1',\n",
       " 'togethercomputer/RedPajama-INCITE-Chat-3B-v1',\n",
       " 'togethercomputer/RedPajama-INCITE-Instruct-3B-v1',\n",
       " 'togethercomputer/StripedHyena-Hessian-7B',\n",
       " 'togethercomputer/StripedHyena-Nous-7B',\n",
       " 'togethercomputer/alpaca-7b',\n",
       " 'togethercomputer/falcon-40b-instruct',\n",
       " 'togethercomputer/falcon-40b',\n",
       " 'togethercomputer/falcon-7b-instruct',\n",
       " 'togethercomputer/falcon-7b',\n",
       " 'togethercomputer/llama-2-13b-chat',\n",
       " 'togethercomputer/llama-2-13b',\n",
       " 'togethercomputer/llama-2-70b-chat',\n",
       " 'togethercomputer/llama-2-70b',\n",
       " 'togethercomputer/llama-2-7b-chat',\n",
       " 'togethercomputer/llama-2-7b',\n",
       " 'upstage/SOLAR-0-70b-16bit',\n",
       " 'wavymulder/Analog-Diffusion',\n",
       " 'zero-one-ai/Yi-34B-Chat',\n",
       " 'zero-one-ai/Yi-34B',\n",
       " 'zero-one-ai/Yi-6B',\n",
       " 'mistralai/Mixtral-8x7B-v0.1',\n",
       " 'HuggingFaceH4/zephyr-7b-beta',\n",
       " 'EleutherAI/pythia-1b-v0',\n",
       " 'togethercomputer/codegen2-16B',\n",
       " 'togethercomputer/replit-code-v1-3b',\n",
       " 'togethercomputer/mpt-7b',\n",
       " 'togethercomputer/mpt-30b-chat',\n",
       " 'google/flan-t5-xxl',\n",
       " 'google/flan-t5-xl',\n",
       " 'togethercomputer/mpt-7b-instruct',\n",
       " 'NumbersStation/nsql-6B',\n",
       " 'togethercomputer/Koala-7B',\n",
       " 'EleutherAI/pythia-6.9b',\n",
       " 'databricks/dolly-v2-12b',\n",
       " 'databricks/dolly-v2-3b',\n",
       " 'EleutherAI/gpt-neox-20b',\n",
       " 'EleutherAI/pythia-2.8b-v0',\n",
       " 'NousResearch/Nous-Hermes-13b',\n",
       " 'togethercomputer/guanaco-65b',\n",
       " 'OpenAssistant/oasst-sft-6-llama-30b-xor',\n",
       " 'Salesforce/instructcodet5p-16b']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see available models\n",
    "model_list = together.Models.list()\n",
    "\n",
    "print(f\"{len(model_list)} models available\")\n",
    "\n",
    "# print the first 10 models on the menu\n",
    "model_names = [model_dict['name'] for model_dict in model_list]\n",
    "model_names[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":\n",
      "\n",
      "\\begin{code}\n",
      "def fibonacci(n):\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    else:\n",
      "        return fibonacci(n-1) + fibonacci(n-2)\n",
      "\\end{code}\n",
      "\n",
      "This function works fine for small values of n, but for larger values of n it takes a long time to compute. I want to optimize it using memoization. I have tried the following code:\n",
      "\n",
      "\n",
      "\\begin{code}\n",
      "def fibonacci(n, memo={}):\n",
      "    if n in memo:\n",
      "        return memo[n]\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    else:\n",
      "        memo[n] = fibonacci(n-1) + fibonacci(n-2)\n",
      "        return memo[n]\n",
      "\\end{code}\n",
      "\n",
      "But this code doesn't work. It gives me a maximum recursion depth error. I have also tried using a dictionary to store the values of n, but that doesn't work either. Can someone please help me with this?\n",
      "\n",
      "Comment: You can use a dictionary to store the values of\n"
     ]
    }
   ],
   "source": [
    "output = together.Complete.create(\n",
    "  prompt = \"code for fibonacci in Python\", \n",
    "  model = 'WizardLM/WizardCoder-Python-34B-V1.0', \n",
    "  max_tokens = 256,\n",
    "  temperature = 0.0,\n",
    "  top_k = 60,\n",
    "  top_p = 0.6,\n",
    ")\n",
    "\n",
    "# print generated text\n",
    "print(output['output']['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '843857f369720d72-MRS',\n",
       " 'status': 'finished',\n",
       " 'prompt': ['code for fibonacci in Python'],\n",
       " 'model': 'togethercomputer/CodeLlama-34b-Instruct',\n",
       " 'model_owner': '',\n",
       " 'num_returns': 1,\n",
       " 'args': {'model': 'togethercomputer/CodeLlama-34b-Instruct',\n",
       "  'prompt': 'code for fibonacci in Python',\n",
       "  'top_p': 0.6,\n",
       "  'top_k': 60,\n",
       "  'temperature': 0,\n",
       "  'max_tokens': 256,\n",
       "  'stop': ['<human>', '\\n\\n'],\n",
       "  'repetition_penalty': None,\n",
       "  'logprobs': None,\n",
       "  'safety_model': None},\n",
       " 'subjobs': [],\n",
       " 'output': {'usage': {'prompt_tokens': 8,\n",
       "   'completion_tokens': 3,\n",
       "   'total_tokens': 11},\n",
       "  'result_type': 'language-model-inference',\n",
       "  'choices': [{'text': '.'}]}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hussein2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
