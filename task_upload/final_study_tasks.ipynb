{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firebase signin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cred = credentials.Certificate(\"../codeinterface-85b5e-firebase-adminsdk-11q7e-837ba92a03.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    }
   ],
   "source": [
    "docs = db.collection('tasks').get()\n",
    "# save docs in a pickle file called old_tasks.pkl\n",
    "tasks = {}\n",
    "for doc in docs:\n",
    "    doc_dict = doc.to_dict()\n",
    "    doc_dict['id'] = doc.id \n",
    "    tasks[doc.id] = doc_dict\n",
    "print(len(tasks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date_string = str(np.datetime64('now'))\n",
    "with open('./saved_data/old_tasks'+today_date_string+'.pkl', 'wb') as f:\n",
    "    pickle.dump(tasks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the documents from the collection\n",
    "for doc in docs:\n",
    "    doc.reference.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = './tasks'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize a list to store all tasks\n",
    "all_tasks = []\n",
    "\n",
    "# Iterate over each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.json'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r') as file:\n",
    "            # Load JSON content\n",
    "            task_data = json.load(file)\n",
    "            # Add the task to the list\n",
    "            all_tasks.append(task_data)\n",
    "\n",
    "all_tasks = np.array(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_transform_unnamed2 - Type:   data_manip\n",
      "retriever - Type:   lengthy_code\n",
      "tokenizer - Type:   edit_code\n",
      "is_bored - Type:   logic\n",
      "t_test - Type:   data_manip_math\n",
      "event_scheduler - Type:   logic\n",
      "order_by_points - Type:   logic\n",
      "encode_message - Type:   logic\n",
      "triple_sum_to_zero - Type:   logic\n",
      "even_odd_count - Type:   logic\n",
      "sum_product - Type:   logic\n",
      "calculator - Type:   fix_code\n",
      "table_transform_unnamed1 - Type:   data_manip\n",
      "login_authenticator - Type:   lengthy_code\n",
      "is_multiply_prime - Type:   logic\n",
      "count_nums - Type:   logic\n",
      "table_transform_named - Type:   data_manip\n"
     ]
    }
   ],
   "source": [
    "# for each task in all_tasks print name and type\n",
    "for task in all_tasks:\n",
    "    print(task['name'], \"- Type:  \", task['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find task in all_tasks with field name  is Average\n",
    "def get_task_index(task_name):\n",
    "    for i in range(len(all_tasks)):\n",
    "        if all_tasks[i]['name'] == task_name:\n",
    "            return i\n",
    "    # raise error if task not found\n",
    "    raise ValueError('Task not found')\n",
    "tutorial_task_index = get_task_index('sum_product')\n",
    "\n",
    "task_sets = [np.array([ get_task_index('even_odd_count'), get_task_index('triple_sum_to_zero'),   get_task_index('table_transform_named'), get_task_index('tokenizer'),\n",
    "                          get_task_index('encode_message'), get_task_index('t_test'), get_task_index('event_scheduler')]),\n",
    "\n",
    "            np.array([ get_task_index('even_odd_count'), get_task_index('is_bored'),   get_task_index('login_authenticator'), get_task_index('is_multiply_prime'),\n",
    "                          get_task_index('count_nums'), get_task_index('table_transform_named'), get_task_index('calculator')]),\n",
    "\n",
    "            np.array([ get_task_index('even_odd_count'), get_task_index('count_nums'),   get_task_index('calculator'), get_task_index('table_transform_unnamed2'),\n",
    "                          get_task_index('login_authenticator'), get_task_index('encode_message'), get_task_index('is_bored')]),\n",
    "\n",
    "            np.array([ get_task_index('even_odd_count'), get_task_index('order_by_points'),   get_task_index('retriever'), get_task_index('triple_sum_to_zero'),\n",
    "                          get_task_index('tokenizer'), get_task_index('event_scheduler'), get_task_index('encode_message')]),\n",
    "\n",
    "            np.array([ get_task_index('even_odd_count'), get_task_index('is_multiply_prime'),   get_task_index('table_transform_unnamed1'), get_task_index('t_test'),\n",
    "                          get_task_index('is_bored'), get_task_index('order_by_points'), get_task_index('triple_sum_to_zero')])]           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_model_tasks = []\n",
    "autocomplete_gpt35_tasks = []\n",
    "autocomplete_llama7_tasks = []\n",
    "autocomplete_llama34_tasks = []\n",
    "chat_gpt35_tasks = []\n",
    "chat_llama7_tasks = []\n",
    "chat_llama34_tasks = []\n",
    "both_gpt35_tasks = []\n",
    "tutorial_task = all_tasks[tutorial_task_index]\n",
    "j = 0\n",
    "for task_set in task_sets:\n",
    "    selected_tasks = all_tasks[task_set]\n",
    "    base_task = {\n",
    "    'function_signatures': [task['function_signature'] for task in selected_tasks],\n",
    "    'task_descriptions': [task['task_description'] for task in selected_tasks],\n",
    "    'tutorial_function_signature': tutorial_task['function_signature'],\n",
    "    'tutorial_task_description': tutorial_task['task_description'],\n",
    "    'unit_tests': [task['unit_test'] for task in selected_tasks],\n",
    "    'exp_condition': 'final_study',\n",
    "    'tutorial_unit_test': tutorial_task['unit_test'],\n",
    "    'task_completed': 0,}\n",
    "    no_model_task = {**base_task,\n",
    "                      'model': 'none',\n",
    "                      'id': 'nomodel_'+str(j),\n",
    "                      'max_tokens': 64,\n",
    "                      'interface_type': 'autocomplete'\n",
    "                      }\n",
    "    autocomplete_gpt35_task = {**base_task,\n",
    "                        'model': 'gpt35',\n",
    "                        'id': 'autocomplete_gpt35_'+str(j),\n",
    "                        'max_tokens': 64,\n",
    "                        'interface_type': 'autocomplete'\n",
    "                        }\n",
    "    autocomplete_llama7_task = {**base_task,\n",
    "                        'model': 'togethercomputer/CodeLlama-7b',\n",
    "                        'id': 'autocomplete_llama7_'+str(j),\n",
    "                        'max_tokens': 64,\n",
    "                        'interface_type': 'autocomplete'\n",
    "                        }\n",
    "    autocomplete_llama34_task = {**base_task,\n",
    "                        'model': 'togethercomputer/CodeLlama-34b',\n",
    "                        'id': 'autocomplete_llama34_'+str(j),\n",
    "                        'max_tokens': 64,\n",
    "                        'interface_type': 'autocomplete'\n",
    "                        }\n",
    "    chat_gpt35_task = {**base_task,\n",
    "                        'model': 'gpt-3.5-turbo',\n",
    "                        'id': 'chat_gpt35_'+str(j),\n",
    "                        'max_tokens': 512,\n",
    "                        'interface_type': 'chat'\n",
    "                        }\n",
    "    chat_llama7_task = {**base_task,\n",
    "                        'model': 'CodeLlama-7b-Instruct',\n",
    "                        'id': 'chat_llama7_'+str(j),\n",
    "                        'max_tokens': 512,\n",
    "                        'interface_type': 'chat'\n",
    "                        }\n",
    "    chat_llama34_task = {**base_task,\n",
    "                        'model': 'CodeLlama-34b-Instruct',\n",
    "                        'id': 'chat_llama34_'+str(j),\n",
    "                        'max_tokens': 512,\n",
    "                        'interface_type': 'chat'\n",
    "                        }\n",
    "    both_gpt35_task = {**base_task,\n",
    "                        'model': 'gpt-3.5-turbo', # gpt-3.5-turbo\n",
    "                        'id': 'both_gpt35_'+str(j),\n",
    "                        'max_tokens': 512,\n",
    "                        'interface_type': 'both'\n",
    "                        }\n",
    "\n",
    "    j+=1\n",
    "    no_model_tasks.append(no_model_task)\n",
    "    autocomplete_gpt35_tasks.append(autocomplete_gpt35_task)\n",
    "    autocomplete_llama7_tasks.append(autocomplete_llama7_task)\n",
    "    autocomplete_llama34_tasks.append(autocomplete_llama34_task)\n",
    "    chat_gpt35_tasks.append(chat_gpt35_task)\n",
    "    chat_llama7_tasks.append(chat_llama7_task)\n",
    "    chat_llama34_tasks.append(chat_llama34_task)\n",
    "    both_gpt35_tasks.append(both_gpt35_task)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    for j in range(len(task_sets)):\n",
    "        db.collection('tasks').document(no_model_tasks[j]['id']+'_'+str(i)).set(no_model_tasks[j])\n",
    "        db.collection('tasks').document(autocomplete_gpt35_tasks[j]['id']+'_'+str(i)).set(autocomplete_gpt35_tasks[j])\n",
    "        db.collection('tasks').document(autocomplete_llama7_tasks[j]['id']+'_'+str(i)).set(autocomplete_llama7_tasks[j])\n",
    "        db.collection('tasks').document(autocomplete_llama34_tasks[j]['id']+'_'+str(i)).set(autocomplete_llama34_tasks[j])\n",
    "        db.collection('tasks').document(chat_gpt35_tasks[j]['id']+'_'+str(i)).set(chat_gpt35_tasks[j])\n",
    "        db.collection('tasks').document(chat_llama7_tasks[j]['id']+'_'+str(i)).set(chat_llama7_tasks[j])\n",
    "        db.collection('tasks').document(chat_llama34_tasks[j]['id']+'_'+str(i)).set(chat_llama34_tasks[j])\n",
    "        #db.collection('tasks').document(both_gpt35_tasks[j]['id']+'_'+str(i)).set(both_gpt35_tasks[j])\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hussein2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
