{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import firestore\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = credentials.Certificate(\"../codeinterface-85b5e-firebase-adminsdk-11q7e-837ba92a03.json\")\n",
    "firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 28 2024 20:34:44 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "It could be more contextualized to the problem at hand, and it could also integrate correct documentation.\n",
      "Mon Jan 29 2024 17:36:18 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "By ensuring that the suggestions meet the requirement and not change or add new functions that are not required.\n",
      "Mon Jan 29 2024 13:32:50 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "By changing the font color of suggestions provided by AI.\n",
      "Sun Jan 28 2024 21:40:32 GMT-0600 (Central Standard Time)\n",
      "The way the AI text was highlighted (maybe because of dark mode?) made it quite hard to read the AI generated text, which made it hard to tell if I wanted to use the suggestion.\n",
      "Suggestions after 2-seconds of inactivity seems bad. It would often interject an annoying amount of crap when I was just thinking, which I would have to remove. Only using the output when prompting for it was much more helpful.\n",
      "Mon Jan 29 2024 14:14:05 GMT-0500 (Eastern Standard Time)\n",
      "What a time and efforts \n",
      "More code suggestions \n",
      "Sun Jan 28 2024 19:49:50 GMT-0500 (Eastern Standard Time)\n",
      "Overall very frustrating to use the AI in this manner. I often wished that I could turn the AI at least while I thought instead of always having it on. I was also never sure what the AI was prompted on, I found my best success by prompting in comments and waiting for a the result, but even then I was looking for single line operations and it would give me multiple lines of code.\n",
      "\n",
      "It also kept trying to generate a main function even though there is no indication that it was needed. \n",
      "More time for the suggestion, or button that activates it. Sometimes while I was thinking about the solution, code would come up and interrupt my train of thought. I felt that I had to constantly check that the AI wasn't adding anything. \n",
      "\n",
      "I also didn't like that the AI's code looked like mine. This makes it hard to backtrack if there was a mistake since I forgot what I wrote and thought out compared to accidentally accepting the AI suggestion.\n",
      "\n",
      "Mon Jan 29 2024 11:59:42 GMT-0500 (Eastern Standard Time)\n",
      "None.\n",
      "The accuracy should be polished up! Please give the user the option to turn it off!\n",
      "Mon Jan 29 2024 00:28:06 GMT-0800 (Pacific Standard Time)\n",
      "AI suggestions need to improve the accuracy.\n",
      "Code suggestions should not be displayed all at once. Next suggestions should be made based on user input rather than trying to write out everything.\n",
      "Sun Jan 28 2024 18:53:56 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "It gave very fragmented code suggestions and wrong formulae not relating to the problems at hand. Copilot generally gives much better code suggestions and would have been more useful on this set.\n",
      "Sun Jan 28 2024 20:34:13 GMT-0500 (Eastern Standard Time)\n",
      "The interface was difficult to manage, I hope that can be improved.\n",
      "I felt the frequency of AI suggestions was too high as it severely impacted my ability to think about the question and the required logic.\n",
      "Most AI suggestions were not relevant to the task and printed irrelevant HTML code on several occasions.\n",
      "Sun Jan 28 2024 21:52:11 GMT-0500 (Eastern Standard Time)\n",
      "NA.\n",
      "I cannot say that it could be improved, because of how far off it was. Instead, it should be replaced by a significantly better assistant. It was very very far off from the correct answers and only hurt my performance.\n",
      "Mon Jan 29 2024 14:39:29 GMT-0500 (Eastern Standard Time)\n",
      "The code generation seems problematic. Nothing generated was useful at all\n",
      "something like copilot that generates actually relevant code would be better. also maybe a \"chat\" option where you can specify what you want it to do\n",
      "Mon Jan 29 2024 13:55:17 GMT-0500 (Eastern Standard Time)\n",
      " \n",
      "\n",
      "AI seemed to recommending empty blocks and text that was not python code. Maybe restrict it to the realm of code in the language that is being used?\n",
      "Mon Jan 29 2024 14:47:16 GMT-0500 (Eastern Standard Time)\n",
      "The AI assistant providing code every 2 seconds threw me off a great deal. I found it difficult to concentrate, and it was very difficult to make the suggestions go away.\n",
      "They should pertain to the task at hand a bit more, and be able to read the user's previous code to get a better grasp of what it should autofill with.\n",
      "Mon Jan 29 2024 17:12:53 GMT+0530 (India Standard Time)\n",
      "\n",
      "\n",
      "Sun Jan 28 2024 19:00:45 GMT-0500 (EST)\n",
      "Was finding it hard and wasn’t going through that much\n",
      "Bu being accurate and and giving relatable suggestions \n",
      "Mon Jan 29 2024 00:33:54 GMT-0500 (Eastern Standard Time)\n",
      "prompts ambiguous.\n",
      "yes.  please see comments i left in my source code\n",
      "Sun Jan 28 2024 22:18:49 GMT-0800 (Pacific Standard Time)\n",
      "The editor was a bit difficult to use; the code would randomly pop up without me expecting (in the middle of me typing, for example), and was often not what I wanted. It also sometimes erased what I had already written when I accidentally pressed tab. Being able to copy the prompt would have been really useful.\n",
      "Oftentimes disrupted my coding process (injecting code unnecessarily) or appeared to give completely irrelevant suggestions.\n",
      "Sun Jan 28 2024 18:20:57 GMT-0800 (Pacific Standard Time)\n",
      "\n",
      "Its debugging skills were not great at all and it gave me very unlikely errors\n",
      "Mon Jan 29 2024 17:41:20 GMT-0500 (Eastern Standard Time)\n",
      "The interaction is quite different from how I use AI for coding in real life. I mostly use copilot which allows me to write a comment and start coding and tries to fill the rest of it in. This study was more of an \"all or nothing\" setting where I either take all of it or none of it. I get that it might have been made to resemble ChatGPT more than CoPilot, but I still had to copy the whole suggestion and remove it which made me extremely not motivated to do the more fine-grained interactions I would with CoPilot or even chatgpt. \n",
      "Not sure whats meant by this. The quality of the predictions? They were adequate, I'd just like more fine-grained control as I describe in the next prompt. \n",
      "Sun Jan 28 2024 22:28:11 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "Better response\n",
      "Mon Jan 29 2024 19:25:35 GMT+0100 (West Africa Standard Time)\n",
      "The coding box was small couldn’t see my codes to know my error\n",
      "Bigger chat boxes to see all codes\n",
      "Mon Jan 29 2024 12:50:00 GMT-0500 (Eastern Standard Time)\n",
      "In one of the questions, pressing the next task button did not do anything. When I pressed the button a second time, it put me two questions ahead. So I think one of my answers (not the last) would be blank.\n",
      "Overall code output was never correct. This could be worked on\n",
      "Sun Jan 28 2024 18:54:29 GMT-0500 (Eastern Standard Time)\n",
      "The general interface could have been made more friendly and the instructions should include more details on how to run and submit code. I was trying to run the 1st problem for so long but wasn't seeing any output despite printing which was very confusing and finally ended up submitting and it turned out to be correct directly. I also Maybe using a traditional online platform might help reduce effort on that.\n",
      "If the AI was specifically meant for coding, I would expect it to give a code or pseudocode almost always in its response which was not there in the final questions as long as I didn't mention that I wanted code in python. Just the theoretical response doesn't really help in those cases. In a few output responses, there wasn;t proper syntax highlighting which I feel is necessary to make the output more easily readable instead of copying to a code editor and then checking.\n",
      "Sun Jan 28 2024 19:19:12 GMT-0500 (Eastern Standard Time)\n",
      "I have zero experience of using pandas. I can ask the AI how to generate code for the pandas task(s) but if things go wrong I would have no idea how to guide the AI to fix it.\n",
      "Its response is too verbose, and I'd like to read less. It would be better if it responded with fewer words but only elaborate if prompted.\n",
      "Mon Jan 29 2024 11:45:45 GMT-0800 (Pacific Standard Time)\n",
      "Thank you for your time!\n",
      "I asked the AI a question like 2*2*23 or something like that, and it responded with a totally bogus answer like \"18\". That was pretty shocking and a little demoralizing to see because if it can't even figure out basic addition, what should I trust it for? \"Other\" AIs do a better job at avoiding gotchas like this.\n",
      "Sun Jan 28 2024 22:08:39 GMT-0800 (Pacific Standard Time)\n",
      "none\n",
      "its working  fine\n",
      "Mon Jan 29 2024 13:03:29 GMT+0100 (GMT+01:00)\n",
      "N/A\n",
      "The AI suggestions should work work more like GitHub copilot; providing solutions inside the development environment.\n",
      "Sun Jan 28 2024 20:01:27 GMT-0800 (Pacific Standard Time)\n",
      "the AI could not give suggestion of where an error is, it gives suggestion of anything that is entered even if it does not make sense.\n",
      "it should be able to give suggestions for possible errors and should be able to make adjustment based on the feedback received can help improve the quality of suggestions it could be by adjusting parameters, using different subsets of data, or even using different training algorithms.\n",
      "Mon Jan 29 2024 10:15:30 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "I like when it generated code examples because they were quicker to read than large blocks of text. \n",
      "Sun Jan 28 2024 19:02:03 GMT-0500 (Eastern Standard Time)\n",
      "\n",
      "It didn't carry forward the context so I couldn't do any debugging of the code it spit out in the beginning. \n",
      "Mon Jan 29 2024 22:16:32 GMT+0000 (Coordinated Universal Time)\n",
      "\n",
      "it should be able to include libraries i wasn't able to test that though, it should be able to able a whole mini project. it should also give suggestions or different options on how to code or solve your problem.\n",
      "Mon Jan 29 2024 00:11:36 GMT-0800 (Pacific Standard Time)\n",
      "None.\n",
      "Better long term reasoning. E.g. it forgot the function definitions for the calculator across two messages\n",
      "Sun Jan 28 2024 23:05:25 GMT-0500 (Eastern Standard Time)\n",
      "I took the test before. But I had missed the part about the AI. \n",
      "This is a retake. \n",
      "Also the IDE has a problem. Some solutions I tried on other environments and they worked fine but the one you gave me has a problem.\n",
      "Make it more context focused. \n",
      "I asked it about code and it gave me information about women’s emancipation\n",
      "Mon Jan 29 2024 16:45:11 GMT-0600 (Central Standard Time)\n",
      "\n",
      "none\n",
      "Mon Jan 29 2024 15:04:32 GMT-0500 (Eastern Standard Time)\n",
      "When submitting code for testing, it would be nice if I could copy the test case that failed (the inputs and expected return) - I understand why copy/paste is disabled except for the contents from editor but it was a bit annoying to memorize a case, exit the alert, type down the input/expected pair and then do it again. \n",
      "none\n",
      "Sun Jan 28 2024 18:48:09 GMT-0500 (Eastern Standard Time)\n",
      "The run output box was quite infuriating as it did not work as expected most of the time.\n",
      "none\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "docs = db.collection('responses').get()\n",
    "# save docs in a pickle file called old_tasks.pkl\n",
    "responses = {}\n",
    "done_count = 0\n",
    "for doc in docs:\n",
    "    doc_dict = doc.to_dict()\n",
    "    doc_dict['id'] = doc.id \n",
    "    if 'entered_exit_survey' and 'finalcomments'  in doc_dict:\n",
    "        print(doc_dict['entered_exit_survey'])\n",
    "        responses[doc.id] = doc_dict\n",
    "\n",
    "        done_count += 1\n",
    "        print(doc_dict['finalcomments'])\n",
    "        print(doc_dict['howaiimproved'])\n",
    "\n",
    "\n",
    "\n",
    "print(done_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil.parser as dparser\n",
    "\n",
    "\n",
    "def process_log(study_data, type = \"none\"):\n",
    "    frustration = int(study_data[\"frustration\"])\n",
    "    performance = int(study_data[\"performance\"])\n",
    "    temporal_demand = int(study_data[\"temporalDemand\"])\n",
    "    physical_demand = int(study_data[\"physicalDemand\"])\n",
    "    effort = int(study_data[\"effort\"])\n",
    "    mental_demand = int(study_data[\"mentalDemand\"])\n",
    "    tlx_score = get_tlx_score(frustration, performance, temporal_demand, physical_demand, effort, mental_demand)\n",
    "    #print(\"TLX Score: \", tlx_score)\n",
    "\n",
    "\n",
    "    completed_time = dparser.parse(study_data[\"completed_task_time\"], fuzzy=True)\n",
    "    date_performed = dparser.parse(study_data[\"date_performed\"], fuzzy=True)\n",
    "    study_completion = get_completion_time(date_performed, completed_time)\n",
    "    #print(\"Completion Time: \", study_completion)\n",
    "\n",
    "\n",
    "    tasks_completed = get_tasks_completed(study_data[\"telemetry_data\"])\n",
    "    #print(\"Tasks Completed: \", tasks_completed)\n",
    "\n",
    "    tasks_attempted = get_tasks_attempted(study_data[\"telemetry_data\"])\n",
    "    #print(\"Tasks Attempted: \", tasks_attempted)\n",
    "\n",
    "    time_to_completion, avg_time_to_completion = get_time_to_completion(study_data[\"telemetry_data\"])\n",
    "    #print(\"Time To Completion: \", time_to_completion)\n",
    "    #print(\"Average Time To Completion: \", avg_time_to_completion)\n",
    "\n",
    "    tasks_skipped = get_tasks_skipped(study_data[\"telemetry_data\"])\n",
    "    #print(\"Tasks Skipped: \", tasks_skipped)\n",
    "\n",
    "    coding_time = get_coding_time(study_data[\"telemetry_data\"])\n",
    "    #print(\"Coding Time: \", coding_time)\n",
    "    additional_metrics = {}\n",
    "    if type == \"autocomplete\":\n",
    "        accept_rate = get_suggestion_acceptance_rate(study_data[\"telemetry_data\"])\n",
    "        additional_metrics = {\n",
    "            \"accept_rate\": accept_rate,\n",
    "        }\n",
    "    \n",
    "    if type == \"chat\":\n",
    "        # count 'assistant_response', 'copy_code' event types in telemetry_data\n",
    "        assistant_response_count = len([event for event in study_data[\"telemetry_data\"] if event[\"event_type\"] == \"assistant_response\"])\n",
    "        copy_code_count = len([event for event in study_data[\"telemetry_data\"] if event[\"event_type\"] == \"copy_code\"])\n",
    "        additional_metrics = {\n",
    "            \"assistant_response_count\": assistant_response_count,\n",
    "            \"copy_code_count\": copy_code_count,\n",
    "        }\n",
    "    \t\n",
    "\n",
    "    dict_metrics  = {\n",
    "\n",
    "        \"tlx_score\": tlx_score,\n",
    "        \"study_completion\": study_completion,\n",
    "        \"tasks_completed\": tasks_completed,\n",
    "        \"tasks_attempted\": tasks_attempted,\n",
    "        \"time_to_completion\": time_to_completion,\n",
    "        \"avg_time_to_completion\": avg_time_to_completion,\n",
    "        \"tasks_skipped\": tasks_skipped,\n",
    "        \"coding_time\": coding_time,\n",
    "        **additional_metrics\n",
    "    }\n",
    "    return dict_metrics\n",
    "\n",
    "def get_tlx_score(frustration, performance, temporal_demand, physical_demand, effort, mental_demand):\n",
    "    return (frustration + performance + temporal_demand + physical_demand + effort + mental_demand) * 5\n",
    "\n",
    "\n",
    "def convert_tool_usage_to_str(tool_usage):\n",
    "    if tool_usage == \"1\":\n",
    "        return \"Strongly Disagree\"\n",
    "    elif tool_usage == \"2\":\n",
    "        return \"Disagree\"\n",
    "    elif tool_usage == \"3\":\n",
    "        return \"Neutral\"\n",
    "    elif tool_usage == \"4\":\n",
    "        return \"Agree\"\n",
    "    elif tool_usage == \"5\":\n",
    "        return \"Strongly Agree\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid tool usage\")\n",
    "\n",
    "\n",
    "def get_completion_time(start_time, end_time):\n",
    "    return end_time - start_time\n",
    "\n",
    "\n",
    "def get_suggestion_acceptance_rate(telemetry_data):\n",
    "    num_accept = len([event for event in telemetry_data if event[\"event_type\"] == \"accept\"])\n",
    "    # only count suggestion_shown when suggestion is not \"\"\n",
    "    num_suggestion_shown = len([event for event in telemetry_data if event[\"event_type\"] == \"suggestion_shown\" and event[\"suggestion\"] != \"\"])\n",
    "    # if num_suggestion_shown == 0:\n",
    "    #     print(\"No suggestions shown!!\")\n",
    "    #     return np.nan\n",
    "    \n",
    "    return num_accept / num_suggestion_shown\n",
    "\n",
    "\n",
    "def get_tasks_completed(telemetry_data):\n",
    "    return len(\n",
    "        [event for event in telemetry_data if event[\"event_type\"] == \"submit_code\" and event[\"completed_task\"] == 1]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_tasks_attempted(telemetry_data):\n",
    "    return len([event for event in telemetry_data if event[\"event_type\"] == \"load_task\"])\n",
    "\n",
    "\n",
    "def get_time_to_completion(telemetry_data):\n",
    "    starts = [event[\"timestamp\"] for event in telemetry_data if event[\"event_type\"] == \"load_task\"]\n",
    "    ends = [\n",
    "        event[\"timestamp\"]\n",
    "        for event in telemetry_data\n",
    "        if event[\"event_type\"] == \"submit_code\" and event[\"completed_task\"] == 1\n",
    "    ]\n",
    "\n",
    "    times = [(end - start) / 1000 for start, end in zip(starts, ends)]\n",
    "    if len(times) == 0:\n",
    "        return 0, np.nan\n",
    "    return times, sum(times) / len(times)\n",
    "\n",
    "\n",
    "def get_coding_time(telemetry_data):\n",
    "    # Get first load task\n",
    "    start = [event[\"timestamp\"] for event in telemetry_data if event[\"event_type\"] == \"load_task\"][0]\n",
    "\n",
    "    # Get last telemetry event\n",
    "    end = telemetry_data[-1][\"timestamp\"]\n",
    "\n",
    "    return (end - start) / 1000\n",
    "\n",
    "\n",
    "def get_tasks_skipped(telemetry_data):\n",
    "    return len([event for event in telemetry_data if event[\"event_type\"] == \"skip_task\"])\n",
    "\n",
    "\n",
    "def get_tasks_skipped(telemetry_data):\n",
    "    return len([event for event in telemetry_data if event[\"event_type\"] == \"skip_task\"])\n",
    "\n",
    "\n",
    "def get_time_verifying_suggestion(telemetry_data):\n",
    "    # Get suggestions\n",
    "    suggestions_shown = [event for event in telemetry_data if event[\"event_type\"] == \"suggestion_shown\"]\n",
    "\n",
    "    suggestions_reviewed = [\n",
    "        event for event in telemetry_data if event[\"event_type\"] == \"reject\" or event[\"event_type\"] == \"accept\"\n",
    "    ]\n",
    "\n",
    "    # Create a hashmap for suggestion reviews.\n",
    "    reviewed_hashmap = {}\n",
    "    for event in suggestions_reviewed:\n",
    "        reviewed_hashmap[event[\"suggestion_id\"]] = event[\"timestamp\"]\n",
    "\n",
    "    # Create a hashmap for times to completion\n",
    "    time_spent_verifying = {}\n",
    "    for event in suggestions_shown:\n",
    "        if event[\"suggestion_id\"] in reviewed_hashmap:\n",
    "            time_spent_verifying[event[\"suggestion_id\"]] = (\n",
    "                reviewed_hashmap[event[\"suggestion_id\"]] - event[\"timestamp\"]\n",
    "            ) / 1000\n",
    "        else:\n",
    "            print(\"No review found for suggestion: \", event[\"suggestion_id\"])\n",
    "\n",
    "    return time_spent_verifying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autocomplete_gpt35_0_4-4767663\n",
      "name Ming Chong Lim email mingchol@andrew.cmu.edu completed 8 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'request_suggestion', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_gpt35_1_1-5457944\n",
      "name Shrikara Varna email svarna@andrew.cmu.edu completed 4 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_gpt35_1_10-7542461\n",
      "name Nirajan Koirala email nkoirala@nd.edu completed 4 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_gpt35_1_2-7342708\n",
      "name Eric Schneider email franz.eric.schneider@gmail.com completed 7 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'request_suggestion', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_gpt35_1_9-7410549\n",
      "autocomplete_gpt35_2_1-3570641\n",
      "name Alfredo Gomez email alfredogomez58@gmail.com completed 3 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_gpt35_2_7-2692440\n",
      "name Glenn Chentianye Xu email chentiax@andrew.cmu.edu completed 4 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'code_reset', 'accept', 'run_code'}\n",
      "autocomplete_gpt35_3_6-9892547\n",
      "autocomplete_gpt35_4_0-1918441\n",
      "name Edward Jin email xdanieh1@gmail.com completed 8 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_llama34_0_10-263435\n",
      "name Ankit Shibusam email ashibusa@andrew.cmu.edu completed 3 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'request_suggestion', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_llama34_0_2-9102663\n",
      "name Dhruv Malik email maliknamya.20@dartmouth.edu completed 4 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_llama34_1_8-5764720\n",
      "name Alan Zhu email yixuanz2@andrew.cmu.edu completed 7 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'request_suggestion', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_llama34_1_9-185578\n",
      "name Amanda Liu email lamanda@mit.edu completed 4 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "autocomplete_llama34_2_5-312886\n",
      "name Sofia Nelson email sn7617@outlook.com completed 2 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'request_suggestion', 'reject', 'save_code', 'code_reset', 'accept', 'run_code'}\n",
      "autocomplete_llama34_4_6-8049061\n",
      "name RAZIK SINGH GREWAL email razikgrewal@gmail.com completed 3 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'run_code'}\n",
      "never accepted sug for autocomplete_llama34_4_6-8049061 name RAZIK SINGH GREWAL email razikgrewal@gmail.com\n",
      "autocomplete_llama7_0_7-8867477\n",
      "autocomplete_llama7_1_7-9057190\n",
      "name Samuel Tenka email samtenka@umich.edu completed 6 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'reject', 'save_code', 'code_reset', 'run_code'}\n",
      "never accepted sug for autocomplete_llama7_1_7-9057190 name Samuel Tenka email samtenka@umich.edu\n",
      "autocomplete_llama7_4_1-6139132\n",
      "name Lily Tsai email tslilyai@mit.edu completed 4 tasks\n",
      "event types {'before_shown', 'load_task', 'submit_code', 'suggestion_shown', 'skip_task', 'reject', 'save_code', 'accept', 'run_code'}\n",
      "chat_gpt35_0_3-3477274\n",
      "name Tu Trinh email tutrinh@berkeley.edu completed 6 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'copy_code', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_gpt35_1_9-1775980\n",
      "name Vikramjeet Das email therealvikramjeet@gmail.com completed 6 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'copy_code', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_gpt35_2_0-3364490\n",
      "name Nathan Gandawa email ngandawa@gmail.com completed 2 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'save_code', 'paste_into_editor', 'clear_chat'}\n",
      "never responded for chat_gpt35_2_0-3364490 name Nathan Gandawa email ngandawa@gmail.com\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706496999597, 'copied_text': 'product = 1\\n    sum = 0'}\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497160290, 'copied_text': 'def sum_product(numbers):\\r\\n    product = 1\\r\\n    total = 0\\r\\n    for num in numbers:\\r\\n        product *= num\\r\\n        total += num\\r\\n    return product, total'}\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497178434, 'copied_text': 'def sum_product(numbers):\\r\\n    product = 1\\r\\n    total = 0\\r\\n    for num in numbers:\\r\\n        product *= num\\r\\n        total += num\\r\\n    return product, total'}\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497209600, 'copied_text': 'def sum_product(numbers):\\r\\n    product = 1\\r\\n    total = 0\\r\\n    for num in numbers:\\r\\n        product *= num\\r\\n        total += num\\r\\n    return product, total'}\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497217698, 'copied_text': 'def sum_product(numbers):\\r\\n    product = 1\\r\\n    total = 0\\r\\n    for num in numbers:\\r\\n        product *= num\\r\\n        total += num\\r\\n    return product, total'}\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497231407, 'copied_text': 'def sum_product(numbers):\\r\\n    product = 1\\r\\n    total = 0\\r\\n    for num in numbers:\\r\\n        product *= num\\r\\n        total += num\\r\\n    return product, total'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497419921, 'copied_text': 'def count_even_odd_digits(n):\\r\\n    even_count = 0\\r\\n    odd_count = 0\\r\\n\\r\\n    # Convert the integer to its absolute value (to handle negative numbers)\\r\\n    n = abs(n)\\r\\n\\r\\n    # Iterate through each digit\\r\\n    for digit in str(n):\\r\\n        if int(digit) % 2 == 0:\\r\\n            even_count += 1\\r\\n        else:\\r\\n            odd_count += 1\\r\\n\\r\\n    return (even_count, odd_count)\\r\\n'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497498288, 'copied_text': 'even_count'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497513025, 'copied_text': ' odd_count'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497538370, 'copied_text': 'result'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497541953, 'copied_text': 'result'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497658255, 'copied_text': 'def count_even_odd_digits(n):\\r\\n    even_count = 0\\r\\n    odd_count = 0\\r\\n    result = []\\r\\n    n = abs(n)\\r\\n    for digit in str(n):\\r\\n        if int(digit) % 2 == 0:\\r\\n            even_count += 1\\r\\n        else:\\r\\n            odd_count += 1\\r\\n    result.append(even_count)\\r\\n    result.append(odd_count)\\r\\n    \\r\\n    return result'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497692370, 'copied_text': 'def count_even_odd_digits(n):\\r\\n    even_count = 0\\r\\n    odd_count = 0\\r\\n    result = []\\r\\n    n = abs(n)\\r\\n    for digit in str(n):\\r\\n        if int(digit) % 2 == 0:\\r\\n            even_count += 1\\r\\n        else:\\r\\n            odd_count += 1\\r\\n    result.append(even_count)\\r\\n    result.append(odd_count)\\r\\n    \\r\\n    return result'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497775327, 'copied_text': 'even_count = 0\\r\\n    odd_count = 0\\r\\n    result = []\\r\\n    n = abs(n)  # Convert to absolute to handle negative numbers\\r\\n    for digit in str(n):\\r\\n        if int(digit) % 2 == 0:\\r\\n            even_count += 1\\r\\n        else:\\r\\n            odd_count += 1\\r\\n    result.append(even_count)\\r\\n    result.append(odd_count)'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497839471, 'copied_text': 'even_count = 0\\r\\n    odd_count = 0\\r\\n    result = []\\r\\n    n = abs(n)\\r\\n    for digit in str(n):\\r\\n        if int(digit) % 2 == 0:\\r\\n            even_count += 1\\r\\n        else:\\r\\n            odd_count += 1\\r\\n    result.append(even_count)\\r\\n    result.append(odd_count)'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497857089, 'copied_text': 'even_count'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706497865501, 'copied_text': 'odd_count'}\n",
      "{'task_index': 1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498086561, 'copied_text': 'def count_nums(arr):\\r\\n    count = 0\\r\\n\\r\\n    for num in arr:\\r\\n        sum_of_digits = 0\\r\\n        if num < 0:\\r\\n            # For negative numbers, start with the negative first digit\\r\\n            sum_of_digits -= abs(num % 10)\\r\\n            num = abs(num) // 10\\r\\n\\r\\n        while num > 0:\\r\\n            sum_of_digits += num % 10\\r\\n            num //= 10\\r\\n\\r\\n        if sum_of_digits > 0:\\r\\n            count += 1\\r\\n\\r\\n    return count'}\n",
      "{'task_index': 1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498155501, 'copied_text': 'for num in arr:\\r\\n        # Extracting digits and handling the negative first digit separately\\r\\n        digits = [int(d) for d in str(abs(num))]\\r\\n        if num < 0:\\r\\n            digits[0] *= -1\\r\\n\\r\\n        # Sum of digits\\r\\n        sum_of_digits = sum(digits)\\r\\n\\r\\n        # Check if sum of digits is greater than 0\\r\\n        if sum_of_digits > 0:\\r\\n            count += 1'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498356224, 'copied_text': 'class Calculator:\\r\\n    def __init__(self):\\r\\n        self.current_number = 0\\r\\n        self.previous_operations = []\\r\\n\\r\\n    def add(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number += a + 20\\r\\n            self.previous_operations.append((prev_number, a, \"add\"))\\r\\n\\r\\n    def subtract(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = self.current_number - a / 10\\r\\n            self.previous_operations.append((prev_number, a, \"subtract\"))\\r\\n\\r\\n    def multiply(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = (self.current_number ** a) / a\\r\\n            self.previous_operations.append((prev_number, a, \"multiply\"))\\r\\n\\r\\n    def divide(self, a):\\r\\n        if isinstance(a, (int, float)) and a != 0:\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = self.current_number / a * 2\\r\\n            self.previous_operations.append((prev_number, a, \"divide\"))\\r\\n\\r\\n    def undo_last_operation(self):\\r\\n        if self.previous_operations:\\r\\n            last_operation = self.previous_operations.pop()\\r\\n            self.current_number = last_operation[0]\\r\\n\\r\\n    def undo_last_k_operations(self, k):\\r\\n        for i in range(min(k, len(self.previous_operations))):\\r\\n            self.undo_last_operation()\\r\\n'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498433713, 'copied_text': 'class Calculator:\\r\\n    def __init__(self):\\r\\n        self.current_number = 0\\r\\n        self.previous_operations = []\\r\\n\\r\\n    def add(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number += a + 20\\r\\n            self.previous_operations.append((prev_number, a, \"add\"))\\r\\n\\r\\n    def subtract(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = self.current_number - a / 10\\r\\n            self.previous_operations.append((prev_number, a, \"subtract\"))\\r\\n\\r\\n    def multiply(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = (self.current_number ** a) / a\\r\\n            self.previous_operations.append((prev_number, a, \"multiply\"))\\r\\n\\r\\n    def divide(self, a):\\r\\n        if isinstance(a, (int, float)) and a != 0:\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = self.current_number / a * 2\\r\\n            self.previous_operations.append((prev_number, a, \"divide\"))\\r\\n        elif a == 0:\\r\\n            # Handle division by zero; can log or raise a custom error if needed\\r\\n            pass\\r\\n\\r\\n    def undo_last_operation(self):\\r\\n        if self.previous_operations:\\r\\n            last_operation = self.previous_operations.pop()\\r\\n            self.current_number = last_operation[0]\\r\\n\\r\\n    def undo_last_k_operations(self, k):\\r\\n        for i in range(min(k, len(self.previous_operations))):\\r\\n            self.undo_last_operation()\\r\\n'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498548301, 'copied_text': 'class Calculator:\\r\\n    def __init__(self):\\r\\n        self.current_number = 0\\r\\n        self.previous_operations = []\\r\\n\\r\\n    def add(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number += a + 20\\r\\n            self.previous_operations.append((prev_number, a, \"add\"))\\r\\n\\r\\n    def subtract(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number -= a / 10\\r\\n            self.previous_operations.append((prev_number, a, \"subtract\"))\\r\\n\\r\\n    def multiply(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            if a == 0:\\r\\n                return  # Early return if \\'a\\' is zero to avoid division by zero\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = (self.current_number ** a) / a\\r\\n            self.previous_operations.append((prev_number, a, \"multiply\"))\\r\\n\\r\\n    def divide(self, a):\\r\\n        if isinstance(a, (int, float)) and a != 0:\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = self.current_number / a * 2\\r\\n            self.previous_operations.append((prev_number, a, \"divide\"))\\r\\n\\r\\n    def undo_last_operation(self):\\r\\n        if self.previous_operations:\\r\\n            last_operation = self.previous_operations.pop()\\r\\n            self.current_number = last_operation[0]\\r\\n\\r\\n    def undo_last_k_operations(self, k):\\r\\n        for i in range(min(k, len(self.previous_operations))):\\r\\n            self.undo_last_operation()\\r\\n'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498683745, 'copied_text': 'class Calculator:\\r\\n    def __init__(self):\\r\\n        self.current_number = 0\\r\\n        self.previous_operations = []\\r\\n\\r\\n    def add(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number += a + 20\\r\\n            self.previous_operations.append((prev_number, a, \"add\"))\\r\\n\\r\\n    def subtract(self, a):\\r\\n        if isinstance(a, (int, float)):\\r\\n            prev_number = self.current_number\\r\\n            self.current_number -= a / 10\\r\\n            self.previous_operations.append((prev_number, a, \"subtract\"))\\r\\n\\r\\n    def multiply(self, a):\\r\\n        if isinstance(a, (int, float)) and a != 0:\\r\\n            prev_number = self.current_number\\r\\n            self.current_number = (self.current_number * a) ** 2\\r\\n            self.previous_operations.append((prev_number, a, \"multiply\"))\\r\\n\\r\\n    def divide(self, a):\\r\\n        if isinstance(a, (int, float)) and a != 0:\\r\\n            prev_number = self.current_number\\r\\n            self.current_number /= a * 2\\r\\n            self.previous_operations.append((prev_number, a, \"divide\"))\\r\\n\\r\\n    def undo_last_operation(self):\\r\\n        if self.previous_operations:\\r\\n            last_operation = self.previous_operations.pop()\\r\\n            self.current_number = last_operation[0]\\r\\n\\r\\n    def undo_last_k_operations(self, k):\\r\\n        for i in range(min(k, len(self.previous_operations))):\\r\\n            self.undo_last_operation()\\r\\n'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706498740000, 'copied_text': 'class Calculator:\\r\\n   def __init__(self):\\r\\n       self.current_number = 0\\r\\n       self.previous_operations = []\\r\\n\\r\\n   def add(self, a):\\r\\n       \"\"\"Adds a (real number) to the current number.\"\"\"\\r\\n       if isinstance(a, (int, float)):\\r\\n           self.previous_operations.append((a, \"add\"))\\r\\n           self.current_number += a + 20\\r\\n\\r\\n   def subtract(self, a):\\r\\n       \"\"\"Subtracts a (real number) from the current number.\"\"\"\\r\\n       if isinstance(a, (int, float)):\\r\\n           self.previous_operations.append((a, \"subtract\"))\\r\\n           self.current_number -= a / 10\\r\\n\\r\\n   def multiply(self, a):\\r\\n       \"\"\"Multiplies the current number by a (real number).\"\"\"\\r\\n       if isinstance(a, (int, float)):\\r\\n           self.previous_operations.append((a, \"multiply\"))\\r\\n           self.current_number = (self.current_number ** a) / a\\r\\n\\r\\n   def divide(self, a):\\r\\n       \"\"\"Divides the current number by a (positive integer).\"\"\"\\r\\n       if isinstance(a, int) and a > 0:\\r\\n           self.previous_operations.append((a, \"divide\"))\\r\\n           self.current_number /= a * 2\\r\\n\\r\\n   def undo_last_operation(self):\\r\\n       \"\"\"Undoes the last operation performed.\"\"\"\\r\\n       if self.previous_operations:\\r\\n           last_operand, last_operation = self.previous_operations.pop()\\r\\n           if last_operation == \"add\":\\r\\n               self.current_number -= last_operand + 20\\r\\n           elif last_operation == \"subtract\":\\r\\n               self.current_number += last_operand / 10\\r\\n           elif last_operation == \"multiply\":\\r\\n               self.current_number = self.current_number ** (-last_operand) * a\\r\\n           elif last_operation == \"divide\":\\r\\n               self.current_number *= a / 2  # Assuming a was stored correctly\\r\\n\\r\\n   def undo_last_k_operations(self, k):\\r\\n       \"\"\"Undoes the last k operations performed.\"\"\"\\r\\n       for _ in range(k):\\r\\n           self.undo_last_operation()\\r\\n'}\n",
      "chat_gpt35_2_6-7315808\n",
      "chat_gpt35_2_6-8421218\n",
      "name Ved Dandekar email vdandeka@andrew.cmu.edu completed 5 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama34_0_9-9042837\n",
      "name Shrey Gupta email shrey2809@gmail.com completed 7 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama34_1_4-8925494\n",
      "name Yishen Chen email cyt046@gmail.com completed 6 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama34_4_7-5075754\n",
      "name Julia Wang email julialujiawang@gmail.com completed 3 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_0_1-5418903\n",
      "name denmark leek email denmarkleek@gmail.com completed 3 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'save_code', 'paste_into_editor', 'clear_chat'}\n",
      "never responded for chat_llama7_0_1-5418903 name denmark leek email denmarkleek@gmail.com\n",
      "{'task_index': -1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706506997233, 'copied_text': 'def sum_product(lst):\\r\\n    if not lst:\\r\\n        return (0, 1)\\r\\n\\r\\n    # Initialize sum and product to 0 and 1, respectively\\r\\n    total_sum = 0\\r\\n    total_product = 1\\r\\n\\r\\n    # Calculate sum and product\\r\\n    for num in lst:\\r\\n        total_sum += num\\r\\n        total_product *= num\\r\\n\\r\\n    return (total_sum, total_product)\\r\\n\\r\\n# Test cases\\r\\nprint(sum_product([]))         # Output: (0, 1)\\r\\nprint(sum_product([1, 2, 3, 4])) # Output: (10, 24)\\r\\n'}\n",
      "{'task_index': 0, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706507285320, 'copied_text': 'def even_odd_count(number):\\r\\n    if not isinstance(number, int):\\r\\n        raise ValueError(\"Input must be an integer\")\\r\\n\\r\\n    even_count = 0\\r\\n    odd_count = 0\\r\\n\\r\\n    # Convert the number to a string to iterate through each digit\\r\\n    for digit in str(abs(number)):\\r\\n        digit = int(digit)\\r\\n        if digit % 2 == 0:\\r\\n            even_count += 1\\r\\n        else:\\r\\n            odd_count += 1\\r\\n\\r\\n    return (even_count, odd_count)\\r\\n\\r\\n# Test cases\\r\\nprint(even_odd_count(-12))  # Output: (1, 1)\\r\\nprint(even_odd_count(123))  # Output: (1, 2)\\r\\n'}\n",
      "{'task_index': 1, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706507658290, 'copied_text': 'def triples_sum_to_zero(nums):\\r\\n    if len(nums) < 3:\\r\\n        return False\\r\\n\\r\\n    nums.sort()  # Sort the list to simplify the process\\r\\n\\r\\n    for i in range(len(nums) - 2):\\r\\n        left = i + 1\\r\\n        right = len(nums) - 1\\r\\n\\r\\n        while left < right:\\r\\n            current_sum = nums[i] + nums[left] + nums[right]\\r\\n\\r\\n            if current_sum == 0:\\r\\n                return True\\r\\n            elif current_sum < 0:\\r\\n                left += 1\\r\\n            else:\\r\\n                right -= 1\\r\\n\\r\\n    return False\\r\\n\\r\\n# Test cases\\r\\nprint(triples_sum_to_zero([1, 3, 5, 0]))          # Output: False\\r\\nprint(triples_sum_to_zero([1, 3, -2, 1]))         # Output: True\\r\\nprint(triples_sum_to_zero([1, 2, 3, 7]))          # Output: False\\r\\nprint(triples_sum_to_zero([2, 4, -5, 3, 9, 7]))   # Output: True\\r\\nprint(triples_sum_to_zero([1]))                   # Output: False\\r\\n'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706508379465, 'copied_text': 'import pandas as pd\\r\\n\\r\\ndef transform_df(input_df):\\r\\n    # Create an empty DataFrame with the desired output columns\\r\\n    output_df = pd.DataFrame(columns=[\\'ic\\', \\'data\\', \\'|| age |\\', \\'blue\\', \\'brown\\', \\'green\\', \\'month\\', \\'age,col\\'])\\r\\n\\r\\n    for index, row in input_df.iterrows():\\r\\n        new_row = {\\r\\n            \\'ic\\': index,\\r\\n            \\'data\\': row[\\'color\\'],\\r\\n            \\'|| age |\\': \\'Under 18\\' if row[\\'age\\'] < 18 else \\'18-25\\',\\r\\n            \\'blue\\': 1 if row[\\'color\\'] == \\'blue\\' else 0,\\r\\n            \\'brown\\': 1 if row[\\'color\\'] == \\'brown\\' else 0,\\r\\n            \\'green\\': 1 if row[\\'color\\'] == \\'green\\' else 0,\\r\\n            \\'month\\': row[\\'dates\\'].month,\\r\\n            \\'age,col\\': f\"{row[\\'age\\']},{row[\\'color\\']}\"\\r\\n        }\\r\\n        output_df = output_df.append(new_row, ignore_index=True)\\r\\n\\r\\n    return output_df\\r\\n\\r\\n# Example usage:\\r\\n# Assuming df is your input DataFrame\\r\\ninput_df = pd.DataFrame({\\r\\n    \\'age\\': [1, 4, 4, 10, 20],\\r\\n    \\'color\\': [\\'blue\\', \\'blue\\', \\'green\\', \\'brown\\', \\'green\\'],\\r\\n    \\'dates\\': [\\'2019-03-06\\', \\'2019-03-05\\', \\'2019-03-10\\', \\'2019-03-07\\', \\'2019-03-01\\']\\r\\n})\\r\\n\\r\\n# Convert \\'dates\\' column to datetime\\r\\ninput_df[\\'dates\\'] = pd.to_datetime(input_df[\\'dates\\'])\\r\\n\\r\\noutput_df = transform_df(input_df)\\r\\nprint(output_df)\\r\\n'}\n",
      "{'task_index': 2, 'event_type': 'paste_into_editor', 'messageAIindex': 0, 'timestamp': 1706508483193, 'copied_text': 'import pandas as pd\\r\\n\\r\\ndef transform_df(input_df):\\r\\n    # Create an empty DataFrame with the desired output columns\\r\\n    output_df = pd.DataFrame(columns=[\\'ic\\', \\'data\\', \\'|| age |\\', \\'blue\\', \\'brown\\', \\'green\\', \\'month\\', \\'age,col\\'])\\r\\n\\r\\n    for index, row in input_df.iterrows():\\r\\n        new_row = {\\r\\n            \\'ic\\': index,\\r\\n            \\'data\\': row[\\'color\\'],\\r\\n            \\'|| age |\\': \\'Under 18\\' if row[\\'age\\'] < 18 else \\'18-25\\',\\r\\n            \\'blue\\': 1 if row[\\'color\\'] == \\'blue\\' else 0,\\r\\n            \\'brown\\': 1 if row[\\'color\\'] == \\'brown\\' else 0,\\r\\n            \\'green\\': 1 if row[\\'color\\'] == \\'green\\' else 0,\\r\\n            \\'month\\': row[\\'dates\\'].month,\\r\\n            \\'age,col\\': f\"{row[\\'age\\']},{row[\\'color\\']}\"\\r\\n        }\\r\\n        output_df = output_df.append(new_row, ignore_index=True)\\r\\n\\r\\n    return output_df\\r\\n\\r\\n# Example usage:\\r\\n# Assuming df is your input DataFrame\\r\\ninput_df = pd.DataFrame({\\r\\n    \\'age\\': [1, 4, 4, 10, 20],\\r\\n    \\'color\\': [\\'blue\\', \\'blue\\', \\'green\\', \\'brown\\', \\'green\\'],\\r\\n    \\'dates\\': [\\'2019-03-06\\', \\'2019-03-05\\', \\'2019-03-10\\', \\'2019-03-07\\', \\'2019-03-01\\']\\r\\n})\\r\\n\\r\\n# Convert \\'dates\\' column to datetime\\r\\ninput_df[\\'dates\\'] = pd.to_datetime(input_df[\\'dates\\'])\\r\\n\\r\\noutput_df = transform_df(input_df)\\r\\nprint(output_df)\\r\\n'}\n",
      "chat_llama7_0_3-7389257\n",
      "name Stephen Ogunjobi email stephenogunjobi@gmail.com completed 2 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_code', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_0_4-6317906\n",
      "name Dennis Mark email dutsinm@gmail.com completed 3 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'copy_code', 'code_reset', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_1_0-3727187\n",
      "name Ananya Joshi email aajoshi@andrew.cmu.edu completed 2 tasks\n",
      "event types {'cancel_request', 'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_1_5-6600304\n",
      "name Satyapriya Krishna email spkrishnaofficial@gmail.com completed 4 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_2_0-9680599\n",
      "name Samuel Adu-Berekorang email samueladu1970@gmail.com completed 2 tasks\n",
      "event types {'load_task', 'submit_code', 'run_code', 'copy_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_2_2-4548890\n",
      "name Anshul Nasery email anasery@uw.edu completed 3 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_from_chat', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "chat_llama7_3_0-5876494\n",
      "name Nathan Gandawa email nathangandawa@gmail.com completed 2 tasks\n",
      "event types {'load_task', 'submit_code', 'skip_task', 'run_code', 'copy_code', 'copy_from_chat', 'code_reset', 'save_code', 'user_message', 'paste_into_editor', 'clear_chat', 'assistant_response'}\n",
      "nomodel_0_5-4335761\n",
      "name Stephen McKay email mckay.sjm98@gmail.com completed 4 tasks\n",
      "event types {'load_task', 'run_code', 'submit_code', 'save_code'}\n",
      "nomodel_1_2-421988\n",
      "name Harshal Chamdal email harshalc@mit.edu completed 6 tasks\n",
      "event types {'load_task', 'run_code', 'submit_code', 'save_code'}\n",
      "nomodel_4_1-7439581\n",
      "name Michael Yang email michael@yangm.tech completed 6 tasks\n",
      "event types {'load_task', 'run_code', 'submit_code', 'save_code'}\n"
     ]
    }
   ],
   "source": [
    "autoocomplete_gpt35_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': [], 'accept_rate': []}\n",
    "autocomplete_llama34_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': [], 'accept_rate': []}\n",
    "autocomplete_llama7_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': [], 'accept_rate': []}\n",
    "chat_gpt35_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': [], 'assistant_response_count': [], 'copy_code_count': []}\n",
    "chat_llama34_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': [], 'assistant_response_count': [], 'copy_code_count': []}\n",
    "chat_llama7_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': [], 'assistant_response_count': [], 'copy_code_count': []}\n",
    "nomodel_metrics = {'num_responses': 0, 'tlx_score': [], 'study_completion': [], 'tasks_completed': [], 'tasks_attempted': [], 'time_to_completion': [], 'avg_time_to_completion': [], 'tasks_skipped': [], 'coding_time': []}\n",
    "for resp in responses.values():\n",
    "    if 'entered_exit_survey' not in resp:\n",
    "        continue\n",
    "    resp_id = resp['id']\n",
    "    print(resp_id)\n",
    "    log_metrics = process_log(resp)\n",
    "    if log_metrics['tasks_completed'] < 2:\n",
    "        continue\n",
    "    print(f'name {resp[\"name\"]} email {resp[\"email\"]} completed {log_metrics[\"tasks_completed\"]} tasks')\n",
    "    # get event types\n",
    "    print(f'event types {set([event[\"event_type\"] for event in resp[\"telemetry_data\"]])}')\n",
    "    if 'autocomplete_gpt35' in resp_id:\n",
    "        autoocomplete_gpt35_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp, type=\"autocomplete\")\n",
    "        # merge dicts\n",
    "        for key in log_metrics:\n",
    "            autoocomplete_gpt35_metrics[key].append(log_metrics[key])\n",
    "        if log_metrics['accept_rate'] <0.001:\n",
    "            print(f'never accepted sug for {resp_id} name {resp[\"name\"]} email {resp[\"email\"]}')\n",
    "            \n",
    "    elif 'autocomplete_llama34' in resp_id:\n",
    "        autocomplete_llama34_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp, type=\"autocomplete\")\n",
    "        for key in log_metrics:\n",
    "            autocomplete_llama34_metrics[key].append(log_metrics[key])\n",
    "        if log_metrics['accept_rate'] <0.001:\n",
    "            print(f'never accepted sug for {resp_id} name {resp[\"name\"]} email {resp[\"email\"]}')\n",
    "    elif 'autocomplete_llama7' in resp_id:\n",
    "        autocomplete_llama7_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp, type=\"autocomplete\")\n",
    "        for key in log_metrics:\n",
    "            autocomplete_llama7_metrics[key].append(log_metrics[key])\n",
    "        if log_metrics['accept_rate'] <0.001:\n",
    "            print(f'never accepted sug for {resp_id} name {resp[\"name\"]} email {resp[\"email\"]}')\n",
    "    elif 'chat_gpt35' in resp_id:\n",
    "        chat_gpt35_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp, type=\"chat\")\n",
    "        for key in log_metrics:\n",
    "            chat_gpt35_metrics[key].append(log_metrics[key])\n",
    "        if log_metrics['assistant_response_count'] < 1:\n",
    "            print(f'never responded for {resp_id} name {resp[\"name\"]} email {resp[\"email\"]}')\n",
    "            # print all events with type paste_into_editor\n",
    "            for event in resp[\"telemetry_data\"]:\n",
    "                if event[\"event_type\"] == \"paste_into_editor\":\n",
    "                    print(event)\n",
    "    elif 'chat_llama34' in resp_id:\n",
    "        chat_llama34_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp, type=\"chat\")\n",
    "        for key in log_metrics:\n",
    "            chat_llama34_metrics[key].append(log_metrics[key])\n",
    "        if log_metrics['assistant_response_count'] < 1:\n",
    "            print(f'never responded for {resp_id} name {resp[\"name\"]} email {resp[\"email\"]}')\n",
    "            for event in resp[\"telemetry_data\"]:\n",
    "                if event[\"event_type\"] == \"paste_into_editor\":\n",
    "                    print(event)\n",
    "    elif 'chat_llama7' in resp_id:\n",
    "        chat_llama7_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp, type=\"chat\")\n",
    "        for key in log_metrics:\n",
    "            chat_llama7_metrics[key].append(log_metrics[key])\n",
    "        if log_metrics['assistant_response_count'] < 1:\n",
    "            print(f'never responded for {resp_id} name {resp[\"name\"]} email {resp[\"email\"]}')\n",
    "            for event in resp[\"telemetry_data\"]:\n",
    "                if event[\"event_type\"] == \"paste_into_editor\":\n",
    "                    print(event)\n",
    "    elif 'nomodel' in resp_id:\n",
    "        nomodel_metrics['num_responses'] += 1\n",
    "        log_metrics = process_log(resp)\n",
    "        for key in log_metrics:\n",
    "            nomodel_metrics[key].append(log_metrics[key])\n",
    "    else:\n",
    "        print('no model found for response ' + resp_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoocomplete_gpt35_metrics\n",
      "{'num_responses': 7, 'tlx_score': [265, 375, 380, 340, 350, 455, 285], 'study_completion': [datetime.timedelta(seconds=2006), datetime.timedelta(seconds=2240), datetime.timedelta(seconds=2265), datetime.timedelta(seconds=2284), datetime.timedelta(seconds=2456), datetime.timedelta(seconds=2316), datetime.timedelta(seconds=1634)], 'tasks_completed': [8, 4, 4, 7, 3, 4, 8], 'tasks_attempted': [8, 6, 6, 8, 5, 6, 8], 'time_to_completion': [[137.493, 134.873, 226.801, 269.65, 261.069, 146.12, 155.127, 558.661], [115.316, 226.867, 1298.0, 848.491], [176.118, 292.668, 528.917, 356.693], [191.283, 146.457, 208.015, 273.293, 378.161, 319.032, 331.631], [249.316, 175.612, 633.999], [74.629, 262.154, 637.68, 1044.376], [53.815, 88.23, 124.503, 304.871, 186.677, 319.081, 352.976, 65.946]], 'avg_time_to_completion': [236.22424999999998, 622.1685, 338.599, 263.98171428571425, 352.9756666666667, 504.70975, 187.01237500000002], 'tasks_skipped': [0, 1, 1, 0, 1, 1, 0], 'coding_time': [1889.798, 2099.374, 2099.343, 2099.473, 2101.621, 2099.754, 1496.106], 'accept_rate': [0.09836065573770492, 0.05555555555555555, 0.06593406593406594, 0.19, 0.11764705882352941, 0.189873417721519, 0.08]}\n",
      "autocomplete_llama34_metrics\n",
      "{'num_responses': 6, 'tlx_score': [430, 245, 350, 285, 145, 370], 'study_completion': [datetime.timedelta(seconds=2459), datetime.timedelta(seconds=2442), datetime.timedelta(seconds=2247), datetime.timedelta(seconds=2219), datetime.timedelta(seconds=2273), datetime.timedelta(seconds=2133)], 'tasks_completed': [3, 4, 7, 4, 2, 3], 'tasks_attempted': [5, 6, 8, 5, 5, 5], 'time_to_completion': [[184.367, 389.776, 241.324], [117.118, 111.46, 101.571, 1413.572], [106.96, 124.771, 295.978, 279.915, 267.377, 188.61, 336.189], [229.044, 435.738, 460.896, 531.301], [440.74, 120.197], [227.962, 271.965, 377.765]], 'avg_time_to_completion': [271.82233333333335, 435.93025, 228.54285714285714, 414.24475000000007, 280.4685, 292.564], 'tasks_skipped': [1, 1, 0, 0, 2, 1], 'coding_time': [2109.516, 2069.65, 2099.553, 2099.565, 1979.58, 2078.869], 'accept_rate': [0.02564102564102564, 0.0425531914893617, 0.0410958904109589, 0.014705882352941176, 0.07246376811594203, 0.0]}\n",
      "autocomplete_llama7_metrics\n",
      "{'num_responses': 2, 'tlx_score': [200, 265], 'study_completion': [datetime.timedelta(seconds=2359), datetime.timedelta(seconds=2264)], 'tasks_completed': [6, 4], 'tasks_attempted': [7, 6], 'time_to_completion': [[102.953, 95.944, 130.157, 793.087, 402.356, 118.582], [92.279, 102.983, 173.597, 1122.009]], 'avg_time_to_completion': [273.84650000000005, 372.717], 'tasks_skipped': [0, 1], 'coding_time': [2095.958, 2100.1], 'accept_rate': [0.0, 0.20930232558139536]}\n",
      "chat_gpt35_metrics\n",
      "{'num_responses': 4, 'tlx_score': [280, 235, 400, 325], 'study_completion': [datetime.timedelta(seconds=2164), datetime.timedelta(seconds=2423), datetime.timedelta(seconds=2194), datetime.timedelta(seconds=2270)], 'tasks_completed': [6, 6, 2, 5], 'tasks_attempted': [7, 7, 5, 7], 'time_to_completion': [[177.908, 87.373, 180.008, 559.456, 673.351, 296.13], [231.304, 79.322, 240.386, 446.571, 269.935, 608.852], [497.404, 882.719], [230.942, 151.154, 370.972, 38.291, 1154.957]], 'avg_time_to_completion': [329.03766666666667, 312.7283333333333, 690.0615, 389.2632], 'tasks_skipped': [0, 0, 2, 1], 'coding_time': [2099.315, 2093.615, 2068.36, 2099.585], 'assistant_response_count': [13, 13, 0, 14], 'copy_code_count': [1, 8, 0, 5]}\n",
      "chat_llama34_metrics\n",
      "{'num_responses': 3, 'tlx_score': [275, 365, 240], 'study_completion': [datetime.timedelta(seconds=2636), datetime.timedelta(seconds=2307), datetime.timedelta(seconds=2243)], 'tasks_completed': [7, 6, 3], 'tasks_attempted': [8, 7, 5], 'time_to_completion': [[226.398, 133.129, 107.213, 565.525, 495.237, 334.676, 183.257], [44.225, 182.838, 313.063, 436.483, 266.836, 403.074], [281.852, 270.383, 1327.221]], 'avg_time_to_completion': [292.205, 274.4198333333333, 626.4853333333333], 'tasks_skipped': [0, 0, 1], 'coding_time': [2093.806, 2061.535, 2099.495], 'assistant_response_count': [23, 10, 29], 'copy_code_count': [0, 0, 2]}\n",
      "chat_llama7_metrics\n",
      "{'num_responses': 8, 'tlx_score': [495, 465, 425, 295, 445, 195, 270, 275], 'study_completion': [datetime.timedelta(seconds=2231), datetime.timedelta(seconds=2505), datetime.timedelta(seconds=2685), datetime.timedelta(seconds=2182), datetime.timedelta(seconds=2185), datetime.timedelta(seconds=2534), datetime.timedelta(seconds=2325), datetime.timedelta(seconds=2285)], 'tasks_completed': [3, 2, 3, 2, 4, 2, 3, 2], 'tasks_attempted': [4, 4, 4, 5, 6, 3, 6, 5], 'time_to_completion': [[761.185, 325.774, 309.257], [920.122, 1142.684], [1708.24, 143.84, 120.203], [328.694, 258.648], [108.18, 436.844, 83.835, 614.413], [1213.14, 380.745], [103.692, 175.287, 354.59], [317.235, 388.807]], 'avg_time_to_completion': [465.4053333333333, 1031.403, 657.4276666666666, 293.67100000000005, 310.818, 796.9425000000001, 211.18966666666665, 353.021], 'tasks_skipped': [0, 1, 0, 2, 1, 0, 2, 2], 'coding_time': [2098.459, 2068.475, 1989.205, 2099.282, 2099.607, 2089.157, 2099.531, 1979.8], 'assistant_response_count': [0, 1, 5, 16, 24, 14, 7, 8], 'copy_code_count': [0, 2, 6, 0, 3, 4, 0, 3]}\n",
      "nomodel_metrics\n",
      "{'num_responses': 3, 'tlx_score': [340, 140, 330], 'study_completion': [datetime.timedelta(seconds=2127), datetime.timedelta(seconds=2248), datetime.timedelta(seconds=2160)], 'tasks_completed': [4, 6, 6], 'tasks_attempted': [5, 7, 7], 'time_to_completion': [[165.183, 352.713, 283.936, 1128.19], [176.17, 81.455, 169.399, 815.372, 283.321, 402.833], [156.256, 140.149, 194.769, 831.179, 369.837, 217.646]], 'avg_time_to_completion': [482.5055, 321.425, 318.306], 'tasks_skipped': [0, 0, 0], 'coding_time': [2100.632, 2099.467, 2099.689]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print metrics for each\n",
    "print('autoocomplete_gpt35_metrics')\n",
    "print(autoocomplete_gpt35_metrics)\n",
    "print('autocomplete_llama34_metrics')\n",
    "print(autocomplete_llama34_metrics)\n",
    "print('autocomplete_llama7_metrics')\n",
    "print(autocomplete_llama7_metrics)\n",
    "print('chat_gpt35_metrics')\n",
    "print(chat_gpt35_metrics)\n",
    "print('chat_llama34_metrics')\n",
    "print(chat_llama34_metrics)\n",
    "print('chat_llama7_metrics')\n",
    "print(chat_llama7_metrics)\n",
    "print('nomodel_metrics')\n",
    "print(nomodel_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_time_to_completion\n",
      "autocomplete_gpt35_metrics\n",
      "357.9530365646259\n",
      "autocomplete_llama34_metrics\n",
      "320.59544841269843\n",
      "autocomplete_llama7_metrics\n",
      "323.28175\n",
      "chat_gpt35_metrics\n",
      "430.27267499999994\n",
      "chat_llama34_metrics\n",
      "397.70338888888887\n",
      "chat_llama7_metrics\n",
      "514.9847708333334\n",
      "nomodel_metrics\n",
      "374.0788333333333\n",
      "tasks_completed\n",
      "autocomplete_gpt35_metrics\n",
      "5.428571428571429\n",
      "autocomplete_llama34_metrics\n",
      "3.8333333333333335\n",
      "autocomplete_llama7_metrics\n",
      "5.0\n",
      "chat_gpt35_metrics\n",
      "4.75\n",
      "chat_llama34_metrics\n",
      "5.333333333333333\n",
      "chat_llama7_metrics\n",
      "2.625\n",
      "nomodel_metrics\n",
      "5.333333333333333\n"
     ]
    }
   ],
   "source": [
    "# get average avg_time_to_completion and tasks_completed\n",
    "print('avg_time_to_completion')\n",
    "print('autocomplete_gpt35_metrics')\n",
    "print(np.nanmean(autoocomplete_gpt35_metrics['avg_time_to_completion']))\n",
    "print('autocomplete_llama34_metrics')\n",
    "print(np.nanmean(autocomplete_llama34_metrics['avg_time_to_completion']))\n",
    "print('autocomplete_llama7_metrics')\n",
    "print(np.nanmean(autocomplete_llama7_metrics['avg_time_to_completion']))\n",
    "print('chat_gpt35_metrics')\n",
    "print(np.nanmean(chat_gpt35_metrics['avg_time_to_completion']))\n",
    "print('chat_llama34_metrics')\n",
    "print(np.nanmean(chat_llama34_metrics['avg_time_to_completion']))\n",
    "print('chat_llama7_metrics')\n",
    "print(np.nanmean(chat_llama7_metrics['avg_time_to_completion']))\n",
    "print('nomodel_metrics')\n",
    "print(np.nanmean(nomodel_metrics['avg_time_to_completion']))\n",
    "\n",
    "print('tasks_completed')\n",
    "print('autocomplete_gpt35_metrics')\n",
    "print(np.nanmean(autoocomplete_gpt35_metrics['tasks_completed']))\n",
    "print('autocomplete_llama34_metrics')\n",
    "print(np.nanmean(autocomplete_llama34_metrics['tasks_completed']))\n",
    "print('autocomplete_llama7_metrics')\n",
    "print(np.nanmean(autocomplete_llama7_metrics['tasks_completed']))\n",
    "print('chat_gpt35_metrics')\n",
    "print(np.nanmean(chat_gpt35_metrics['tasks_completed']))\n",
    "print('chat_llama34_metrics')\n",
    "print(np.nanmean(chat_llama34_metrics['tasks_completed']))\n",
    "print('chat_llama7_metrics')\n",
    "print(np.nanmean(chat_llama7_metrics['tasks_completed']))\n",
    "print('nomodel_metrics')\n",
    "print(np.nanmean(nomodel_metrics['tasks_completed']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hussein2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
